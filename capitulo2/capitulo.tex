\chapter{Estudio del Problema}

Como se mencionó al final del capítulo anterior, la investigación vigente del fenómeno estudiado en el presente trabajo ha concluido en generar distintas hipótesis para explicar el mal rendimiento presentado por los sockets de internet en escenarios de concurrencia, más sin corroborar la validez de ninguna experimentalmente. Para ser exactos, y reiterando lo anterior, las sospechas se pueden agrupar en tres aristas distintas: Problemas de operación en primitivas del sistema, problemas de operación a nivel de canales de comunicación de hardware y problemas de operación en los mecanísmos de administración de recursos y balanceo de carga.

En el presente capítulo se estudian las tres líneas hipotéticas responsables del problema, inspeccionando en distintos niveles el funcionamiento del sistema, indagando en las operaciones teóricas de cada funcionamiento y contrastando dicho planteamiento a resultados experimentales obtenidos en cada caso. Es fruto de cada una de las siguientes subsecciones un análisis profundo del aspecto problemático estudiado, junto con una conclusión sobre el mismo. Así también, es fruto del presente capítulo un veredicto sobre cuales -Y en qué medida- de los problemas estudiados tienen verdadera responsabilidad en el fenómeno estudiado, de modo de confeccionar un marco de trabajo que nos permita empezar a postular enfoques de trabajo que paleen la problemática en cuestión.

\section{Estudio de Operación Primitivas de sincronización del Sistema}

La primera hipótesis a estudiar plantea que el bajo rendimiento de la operación de la interfaz de red -Ilustrada en nuestro caso de estudio por medio de sockets UDP- en escenarios de concurrencia, es causado por un mal desempeño de las estructuras que proveen los mecanismos de sincronización para dichos escenarios. Cómo se mencionó en el capítulo anterior, la capacidad multiprocesador de las computadoras modernas provee de un mayor poder de cómputo que se postula a ser aprovechado por medio del uso de técnicas de programación paralela, con el cuidado de que, en esos contextos de trabajo, los sistemas operativos deben estar preparados para atender situaciones de conflicto en el acceso a los recursos compartidos. Para éste propósito, se disponen de los mecanísmos de sincronización ya repasados en secciones anteriores que para estructuras de bajo nivel, cómo son los sockets de internet provistos por el propio sistema operativo- emplean el uso de mecanísmos de sincronización de bajo nivel como lo son los spinlocks, que protegen ciertas secciones de la estructura, tal y como se repasó en el capítulo anterior.

En éste caso, la priemra hipótesis describe que el causante del mal rendimiento al incorporar concurrencia en las lecturas a un socket es generado derechamente por dichas estructuras de protección en el acceso, situación causaría un fenómeno denominado \emph{Contención de Recurso}.

\begin{defn}[ver \cite{paper:resourceContention}] \textbf{Contención de Recurso} corresponde a un estado de conflicto en el acceso a un recurso compartido entre distintas componentes de un sistema, producido por una situación de competencia en el acceso al mismo que puede degenerar en escenarios problemáticos, como situaciones de bloqueo, conflictos por situaciones de carrera y degradación de performance, entre otros.
\end{defn}

Para ratificar el planteamiento anterior, se hizo un estudio de llamadas a sistema siguiendo otros modelos de recopilación de datos ya evaluados en otros trabajos exitosos \cite{slides:hpPerf} que permitiese vislumbrar la operación de las primitivas de sincronización operativas en el caso de estudio, a medida que se van agregando hilos de procesamiento en el consumo de una misma estructura socket compartida entre todos los hilos. En ésta linea, es interesante analizar cómo el socket mismo actúa como un potencial punto de contención, o como alguna de las estructuras de limitación en sus acceso (como es el spinlock del socket mismo) tienen responsabilidad en el rendimiento general.

\subsection{Estudio de Llamadas de sistema}

La operación de las primitivas de sincronización que actúan en los procesos de bajo nivel del sistema operativo tienen la característica de estar determinadas por el uso de llamadas a funciones del sistema, ello pues es el mismo sistema operativo (o mejor dicho su núcleo) el que provee una interfaz simple para invocar dicha operación. Cómo son llamadas a sistema, es posible cuantificar cuando y cómo se realiazan las mismas, pudiendo modelar el proceso completo por medio de éste mecanismo.

Cómo en nuestro caso interesa estudiar el comportamiento de primitivas de sincronización de bajo nivel como son los spinlocks, se debe contemplar la API\footnote{Abreviatura de \emph{Application Programming Interface}, ó Interfaz de Programación de Aplicaciones en español.} con que trabaja el sistema para controlar éstas estructuras, ello pues, a pesar de que la estructura spinlock está bien definida, existen distintas funciones que proveen variantes en el funcionamiento de los spinlocks, y dichos escenarios son presentables a lo largo de la ejecución del caso de prueba del estudio. El objetivo de éste estudio concierne un análisis cuantitativo de la cantidad de llamadas a sistema que sean bloqueantes sobre estructuras bloqueantes de tipo spinlock y del tiempo que el sistema gasta en dichas condiciones.

En Linux los spinlocks se representan con estructuras \verb=spinlock_t= (incluidas en el archivo \verb= <linux/spinlock.h>=) que básicamente consisten en un campo de lock con un valor 1 (si está libre) o 0 (si está ocupado). Existen diversas funciones de atención que aplican distintos tipos de bloqueo \cite{book:spinlocks}:

\begin{description}
\item[void spin\_lock\_init(spinlock\_t *lock);] Inicializa una estructura spinlock y setea su valor inicial en 1.
\item[void spin\_lock(spinlock\_t *lock);] Es el bloqueo básico del sistema para tomar el lock. Consistente en la espera del lock hasta su valor 1 para luego setearlo en 0. Dicha espera se realiza con ciclos de \emph{busy-waiting} hasta que se brinde acceso. Es un bloqueo interrumpible por el sistema operativo, tanto por interrupciones de software como de hardware, dando paso a situaciones como que la CPU determine enviar el proceso responsable de la llamada a dormir por falta de recursos, memoria, etc.
\item[void spin\_lock\_irq(spinlock\_t *lock);] Bloqueo que deshabilita interrupciones del procesador local antes de adquirir el spinlock. Se debe cuidar de reactivar las interrupciones luego de liberado el lock.
\item[void spin\_lock\_irqsave(spinlock\_t *lock, unsigned long flags);] Similar a la operación de \verb=spin_lock_irq=, pero con la diferencia de que almacena el estado de interrupción previo en el valor \verb=flags=, de manera de que puede restablecerlo facilmente luego de liberar el lock.
\item[void spin\_lock\_bh(spinlock\_t *lock)] Similar a \verb=spin_lock_irq= con la diferencia de que sólo deshabilita las interrupciones de software, manteniendo habilitadas las interrupciones por hardware del sistema.
\item[int spin\_trylock(spinlock\_t *lock);] Para operaciones no bloqueantes para el uso de spinlocks. Retorna cero en caso de fallo al obtener el lock. No deshabilita interrupciones.
\item[bool mutex\_spin\_on\_owner(struct mutex *lock, struct task\_struct *owner)] Bloqueo que opera sobre una estructura de exclusión mutua (mutex) que utiliza el enfoque de \emph{Read-Copy-Update} (RCU), en donde los lectores son no bloqueantes. Ésta estructura tiene una sobrecarga menor que las anteriores; Sin embargo, las actualizaciones son más costosas ya que las versiones anteriores de la estructura de datos se deben guardar con el fin de dar cabida a los lectores ya existentes que se sincronizan a través de las barreras del mutex. Utilizando el enfoque de la RCU el bloqueo con esta estructura mutex asegura que la operación \emph{Test-and-Set} se ejecute en la misma CPU del propietario del lock, lo que reduce la cantidad de comunicación de memoria caché (y por consiguiente, el efecto de contención).
\end{description}

Asociadas a las anteriores llamadas de sistema están las variantes \verb=*_unlock*= que permiten liberar el elemento de bloqueo (seteando el valor del lock a 1) para recuperar así su disponibilidad para otros procesos.

Para poder rescatar las llamadas a sistema existen herramientas de software de bajo nivel, creados por los mismos desarrolladores del núcleo de Linux que permiten realizar la tarea que nos proponemos en éste caso.

\subsubsection{Perf}
Perf \cite{slides:perfTools} o también llamado \emph{Perf\_events\footnote{Mayor documentación disponible en \url{https://perf.wiki.kernel.org/}}} es una herramienta de análisis de performance para entornos Linux. Corresponde a un subsistema del mismo kernel de Linux que provee todo un framework para el estudio de performance del sistema y de programas por medio de la captura de una amplia variedad de fuentes de datos. Perf es capaz de colectar datos por operatividad de software (contadores de software, \emph{tracepoints}, ejecución de funciones, paso a assembler, etc.) y también colectar información a nivel de hardware (manejo de PMU, lectura de \emph{Performance Counters}, etc.), características que lo postulan como uno de los sistemas más completos y flexibles para las tareas de profilling de aplicaciones y sistemas, y que lo hacen una buena herramienta para el actual estudio.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.45]{imagenes/perfArchitecture.png}
	\caption{Arquitectura de operación del framework provisto por \emph{Perf}.}
	\label{fig:perfFramework}
\end{figure}

Además de su gran capacidad para colectar datos, Perf es una herramienta de sencillo uso, pues su funcionamiento se basa en la supervisión de un determinado proceso o tarea de la cual construye un archivo con la información que se haya seleccionado a colectar \cite{article:perf}. Para ello, se pueden emplear las utilidades \verb=perf-record= y \verb=perf-stat= las que trabajan supervisando un determinado proceso y proveiendo paginas de datos al espacio del kernel que son rellenadas con información del sistema de dicho proceso y son retornadas al proceso responsable construyendo un informe a modo de output\footnote{La asignación del espacio de páginas a rellenar se hace por medio de la utilidad \verb=mmap= de Linux, que provee direcciones virtuales en un proceso para almacenar información.} (Ver figura \ref{fig:perfRecord}). Posteriormente, se pueden realizar operaciones de análisis más exhaustivo sobre dichos archivos de resultados.

El potencial de ésta herramienta la perfila como una utilidad indispensable para el estudio en cuestión. En primer lugar por su capacidad de análisis de ejecución de código que permite obtener información cuantificada de las llamadas a sistema y de la dinámica del árbol de llamados\footnote{Acá explicar brevemente que es un árbol de llamados} que permite reconocer la naturaleza de las funciones involucradas en el caso de estudio. En segunda instancia Perf es una estupenda herramienta para la recolección de datos de hardware al aprovechar el uso de la \emph{Performance Monitoring Unit (PMU)} del hardware del sistema, una característica que será revisada en detalle en secciones posteriores.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.45]{imagenes/perfRecord.png}
	\caption{Esquema de captura de datos de un programa usando el comando \emph{perf-record}.}
	\label{fig:perfRecord}
\end{figure}

\subsubsection{FTrace}
Ftrace\footnote{Mayor documentación disponible en \url{http://elinux.org/Ftrace}} es otra poderosa herramienta para estudios de profiling disponible para sistemas Linux \cite{paper:FTraceSony}. Su funcionamiento opera de naturaleza muy intima con respecto al kernel mismo pues su recolección de datos se basa en el rastreo de la ejecución de funciones de forma dinámica en el espacio de kernel, lo que lo hace una estupénda utilidad para el estudio de llamadas al sistema pudiendo recuperar datos como el tiempo de ejecución y cantidad de ocurrencia de las mismas.

Para su uso, FTrace opera como un verdadero framework del sistema sobre el kernel, del cual se pueden usar distintos métodos de rastreo de llamadas basados en distintos algoritmos. Una de las funciones más poderosas de FTrace es el resultado que se puede obtener por medio de la instrumentación de código, que se refiere a la práctica de incorporar a los programas a analizar \emph{tracepoints}, que son declaraciones explicitas de secciones de código a analizar y registrar. A pesar de que ésta característica es muy cómoda para programas propios, en el caso del análisis de funciones y llamadas de sistema la instrumentación de código es una característica obviable, siendo sólo necesaria la precisión de qué llamadas considerar en el análisis pues el sistema es flexible para hacer análisis directamente de funciones del sistema. El uso de ésta herramienta es muy flexible, siendo activable a disposición del usuario y conservando un registro de resultados. Además, FTrace es altamente configurable pudiendo explicitar filtros que usar como registros para las llamadas de sistema a analizar.

El provecho que se puede sacar de ésta herramienta es usar su capacidad para cuantificar tiempo de funciones del kernel para estudiar la atomicidad de las llamadas bloqueantes del sistema. Así por ejemplo, se pretende determinar el tiempo que se pasa en estados bloqueantes de spinlocks (que terminan siendo pasos de \emph{busy-waiting}) en los cuales sólo se pierde tiempo por caso de contención.

\subsection{Metodología de Experimentación}

Dado que la naturaleza de éste estudio se relaciona con el comportamiento de funciones del sistema que administran las primitivas de acceso y sincronización del Interet socket, se realizarán las configuraciones pertinentes para cada herramienta a fin de contemplar dichos puntos de análisis. En el caso de Perf, la recolección de datos clásica se realizará con la herramienta \verb=perf-record=, y se realiza un post-procesamiento sobre el archivo de reporte generado, para colectar los datos estadísticos asociados a las distintas funciones de manejo de spinlock antes mencionadas\footnote{Correspondiente a la ejecución del proyecto \url{https://github.com/sebablasko/Test_MultiThreadStressTransmision} con privilegios de administrador.}.

Por otro lado, para el estudio con FTrace la configuración resulta un poco más compleja. Dado que es una herramienta de traceo que opera inspeccionando las llamadas de funciones de sistema, la activación de FTrace sobrecarga el funcionamiento del sistema general. Por ello, FTrace se debe activar y desactivar manualmente para analizar sólo los instantes de operación de la prueba de interés. Además, dado el amplio espectro de funciones disponibles para inspeccionar con el framework, deben emplear las funciones de filtrado de funciones a tracear que provee el mismo framework. En pos de capturar funciones en línea con la diniámica del spinlock del Internet socket, se configuró FTrace para capturar estadísticas de todas aquellas funciones definidas anteriormente.

\begin{lstlisting}[style=BashInputStyle, label={code:ftrace}, caption={Configuración de filtros de FTrace sobre funciones a estudiar.}, captionpos=b]
[sebastian@labs-vhost ~]$ echo *spin* > /sys/kernel/debug/tracing/set_ftrace_filter 
[sebastian@labs-vhost ~]$ cat /sys/kernel/debug/tracing/set_ftrace_filter 
mutex_spin_on_owner
spin_msec
_spin_trylock
_spin_lock_irqsave
_spin_lock_irq
_spin_lock
_spin_unlock_irqrestore
_spin_lock_bh
_spin_trylock_bh
_spin_unlock_bh
bit_spin_lock
kvm_vcpu_on_spin
\end{lstlisting}

Por otra parte, el encendido y apagado del framework mismo se configuró como parte del programa de prueba\footnote{\url{https://github.com/sebablasko/Test_UDPTrace/}}. En el mismo se configuró la opción \verb=set_ftrace_pid= para explicitar la inspección de FTrace sólo para el script de prueba, además del uso de la utilidad \verb=trace_marker= para instrumentar porciones de código de la prueba (como creación de threads, y término de consumo de datos) que permitiese una mayor facilidad al momento de estudiar los logs de ejecución recuperados.

\subsection{Resultados}
Nos topamos con que las tendencias de tiempos son similares a las de los tiempos de esas llamadas, luego, hay una correlacion de esta estructura inhenrente al socket es la que causa el cuello de botella: indicio, el socket entero está siendo contenido por el spinlock de su estructura.

\subsubsection{Perf}
Gráfico de resultados de perf

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.5]{resultados/perfdetalle-crop.pdf}
	\caption{Resultados experimentales de los porcentajes de ejecución de las llamadas a sistema recolectadas por \emph{Perf}.}
	\label{fig:resPerf}
\end{figure}

Para reconocer mejor la dinámica de consumo de tiempos en las funciones inspeccionadas en el caso de estudio, se usaron los reportes generados por Perf para construir un nuevo tipo de visualización de llamadas a sistema: Un \emph{Call-Graph-Chart} (Ver imagen \ref{fig:rescallGraph}), de manera de poder reconocer los bloques de funciones más repetidos en la ejecución del caso de prueba. Para ésta visualziación se aporvechó el script \emph{gprof2dot}\footnote{\url{https://github.com/jrfonseca/gprof2dot}}.
\begin{figure}[!h]
	\centering
	\includegraphics[scale=.5]{imagenes/fcfm}
	\caption{Visualización de call-graph identificando las llamadas a sistema y sus pesos en el caso de prueba.}
	\label{fig:detalleFtrace}
\end{figure}

\subsubsection{FTrace}
Gráfico de resultados de FTrace
\begin{figure}[!h]
	\centering
	\includegraphics[scale=.5]{resultados/detalleFtrace-crop.pdf}
	\caption{Resultados experimentales de los tiempos de ejecución de las llamadas a sistema recolectadas por \emph{FTrace} para la adquisición y liberación del lock.}
	\label{fig:}
\end{figure}

Ahora hablar de los tiempos totales de bloqueo
\begin{figure}[!h]
	\centering
	\includegraphics[scale=.5]{resultados/sumaFtrace-crop.pdf}
	\caption{Tiempos totales de bloqueo sobre el lock por las distintas llamadas de sistema capturadas por \emph{Ftrace} en el caso de estudio juntos con una curva de aproximación de tendencia.}
	\label{fig:sumaFtrace}
\end{figure}

Finalmente, si se revisan las tendencias separando las distintas operaciones de bloqueo y liberación del lock
\begin{figure}[h!]
	\centering
	\hspace*{\fill}
	\subfigure[Funciones de Bloqueo]{
		\includegraphics[width=.47\textwidth]{resultados/bloqueantesftrace-crop.pdf}
		\label{fig:ftracebloquea}
	}\hfill
	\subfigure[Funciones de Liberación]{
		\includegraphics[width=.47\textwidth]{resultados/liberadorasFtrace-crop.pdf}
		\label{fig:ftracelibera}
	}
	\caption{Graficos con tendencias de tiempos del lock capturados con \emph{Ftrace} a lo largo del caso de estudio.}
	\label{fig:Ftracebloquealibera}
	\hspace*{\fill}
\end{figure}



\subsection{Análisis y Discusión de Resultados}
Aka un análisis general de los resultados en términis de gráficos obtenidos

\subsubsection{TraceDisplay}
Para poder obtener una interpretación adicional del fenómeno reconocido, se construyó una herramienta de visualziación de las llamadas a sistema para funciones de sincronización que permitiese reconocer las porciones de tiempo que tomasen en cada procesador dichas funciones. Para ello, la herramienta denominada \emph{TraceDisplay} recibe un log generado con \emph{FTrace} que incluya las llamadas de sistema yá filtradas, y construye un mapa de tiempo coloreado donde se pueden apreciar las porciones de tiempo que consume cada llamada y desde cual CPU se originan. El resultado se puede apreciar en la imagen \ref{fig:traceDisplay} donde se ilustra el caso de analizar [[AKA FALTA EXPLICAR EL CASO EVALUADO]].

Éste subproducto de la investigación principal junto con su documentación de uso está publicado\footnote{Disponible en \url{https://github.com/sebablasko/TraceDisplay}} y disponible para su uso.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.34]{imagenes/traceVisualization.png}
	\caption{Visualización de aplicación de llamadas de sistema de sincronización realizadas entre procesadores, generada con la herramienta TraceDisplay.}
	\label{fig:traceDisplay}
\end{figure}

Resultados como el mostrado en la figura \ref{fig:traceDisplay} ilustran como, en la práctica, las operaciones de bloqueo se terminan ejecutando serializadamente, aún cuando son distintos los CPU que los originen. Esto producto de que es una misma estructura la que se está compartiendo y así, se puede deducir un sobrecosto producido por dicha serialziación en el acceso.

\subsection{Conclusiones}
A raíz del estudio de operación de primitivas de sincronización del sistema se pueden rescatar varios aspectos interesantes:
\begin{itemize}
\item La tendencia en los costos de tiempo son crecientes a medida que se agregan hilos que consumen el mismo socket. Ello tanto en porcentaje de llamadas de sistema, como también en tiempos netos en esas llamdas.
\item Se identifican distintas estructuras bloqueantes para sincronización activas a lo largo del caso de estudio, sin embargo se destacan estructuras de tipo spinlock como las más reiteradas en el rastro de llamadas a sistema. Spinlock propio del mecanísmo de protección de la estructura socket accesada.
\item Se destaca una tendencia de naturaleza logaritmica en el crecmimiento de tiempos que toman las llamadas bloqueantes sobre el spinlock del socket, ajustada con un coeficiente de determinación superior al 90\%.
\end{itemize}
A raíz de lo anterior, se reconoce en el spinlock de protección del socket como un punto de cuello de botella al momento de emplear accesos concurrentes a una estructura socket. Ello al actuar como un punto de bloqueo que termina serializando el acceso al consumo de datos y que, lejos de reducir los tiempos paralelizando el acceso, los aumenta al serialziarlos y deber coordinar los hilos para ello.

\section{Estudio de Canales de Comunicación de Hardware}
La segunda hipótesis para explicar la mala performance del caso de estudio presentado se centra en una componente de hardware más que de software. Cómo ya se mencionó, la capacidad multiprocesador de que se dispone en equipos modernos no es un recurso fácil de aprovechar, de hecho requiere una sofisticada operación y diseño tanto de las aplicaciones que solicitarán recursos, como del sistema operativo que ha de administrarlos. Como se repasó en secciones anteriores, la capacidad de paralelísmo viene dada gracias a un conjunto de protocolos y algoritmos de muy bajo nivel que coordinan y mantienen en estado coherente las distintas componentes de datos para los diferentes procesadores \cite{paper:MESI, paper:snoop}, sin embargo, por muy sofisticados que dichos mecanismos sean, las nuevas tecnologías de hardware que prometen velocidades de trasnferencia y acceso nunca antes imaginiadas podrían significar un problema para éstas componentes, sobrepasándolos de cierta forma.

Es precisamente en ésta línea que se establece la segunda hipótesis. En éste caso, se adjudican las responsabilidades por el mal rendimiento presentado a un problema de contención de recursos (nuevamente al spinlock de los sockets), pero ésta vez relacionado a la persistencia en el acceso al mismo y a la disponibilidad que se da del mismo a través de los mecanismos antes mencionados. En las arquitecturas modernas, los protocolos \emph{MESI} y de \emph{SNOOP} son cruciales en la operación de ejecuciones paralelas para garantizar integridad en los datos, pero las arquitecturas modernas proponen nuevas distribuciones de los componentes internos de hardware, dotando de canales de comunicación de mayor velocidad de transmisión y reasignando los recursos físicos. Ésta hipótesis plantea la posibilidad de que el degradamiento del caso de estudio sea generado por un fenómeno de \emph{Caché Bouncing}.

\begin{defn}[ver \cite{paper:cachebouncing}] \textbf{Caché Bouncing} corresponde a un fenómeno producido en entornos multiprocesador, cuando distintas CPU realizan modificaciones a una linea de caché especifica que está siendo referenciada por varios procesadores. La modificación de la linea modificada se trasnfiere de caché en caché según los protocolos de consistencia del sistema. Éste fenómeno impone una significativa carga en el bus de memoria y los canales de comunicación afectados pudiendo degenerar en una degradación generalizada del sistema.
\end{defn}

En ésta línea, el fenómeno de \emph{Cache Bouncing} se podría manifestar dada la arquitectura del sistema, la que al contemplar bancos de memoria diversos, algunos compartidos y otros exclusivos para los núcleos de procesamiento, podría estar manifestandose como resultado de las modificaciones concurrentes de los distintos procesadores sobre la estructura socket compartida, y más precisamente sobre el spinlock del socket. Lo anterior combinado a la operación de los protocolos de consistencia y correctitud para las lineas de caché del sistema postulan evidencia que hace perfectamente posible el que se esté generando un overhead de comunicación que termine sobrecargando los tiempos totales de ejecución del caso de estudio.

Para validar la hipótesis anterior es preciso un cabal entendimiento de la arquitectura de hardware objetivo, a fin de poder localizar puntos de contención junto con una comprensión importante de la \emph{Performance Monitoring Unit} que provee el fabricante, lograr configurarla y aprovecharla para la recolección de datos finales. En las siguientes secciones se realiza un estudio de la arquitectura descrita en la figura \ref{fig:pc3} del equipo sobre el que se realizan las pruebas experimentales reales. Posteriormente se realiza un análisis experimental de las tendencias presentes en una tarea de acceso concurrente como la descrita en el caso de estudio de ésta investigación con el fin de corroborar o descartar las sospechas ya mencionadas del efecto de contención y \emph{caché bouncing} por eventos de perfomance de hardware.

\subsection{Características de Arquitecturas de Hardware Modernas}
Cómo ya se mencionó en secciones anteriores los fabricantes de partes y piezas de computadoras están constantemente desarrollando importantes avances, de la mano con el desarrollo técnico de piezas que brinda mejores componentes de hardware cada día. La linea de desarrollo de infraestructura de hardware principal de los computadores no está excenta de dicha evolución. En secciones anteriores se presentó como las arquitecturas han evolucionado desde el primer esquema \emph{SMP} propuesto con la distribución \emph{FSB}, pasando luego por nuevas configuraciones como \emph{DIB} y \emph{DHSI}, entre otras. Sin embargo, el desarrollo ha sido constante y hoy las arquitecturas han degenerado en esquemas bastante más complejos en pos de aprovechar al máximo la capacidad de los procesadores en la línea del paralelísmo.

\subsubsection{Arquitectura Intel QuickPath}
Al año 2008, el fabricante de procesadores Intel® lanzó al mercado una nueva tecnología denominada \emph{Intel QuickPath Architecture} \cite{paper:quickpath} la que platea un nuevo esquema organizacional de los componentes internos de la placa principal de las computadoras, así como también un nuevo esquema de conectividad entre los componentes de la misma, prometiendo entre otras cosas: Un sistema más confiable, eficiente, rápido y escalable, que podría aprovechar mejor la capacidad de los múltiples procesadores de su misma linea. La apuesta de Intel resultó todo un éxito. Rápidamente \emph{QuickPath} se posicionó en el mercado para competir con la tecnología \emph{HyperTransport} desarrollada por \emph{AMD}\footnote{AMD es el principal competidor de Intel en la industria de la manufactura de microprocesadores. \url{http://www.gestiopolis.com/intel-vs-amd-guerra-procesador/}}, abriendo paso definitivamente a una era, dejando atras el enfoque \emph{FSB}.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.5]{imagenes/quickpath2.png}
	\caption{Diseño organizacional de los componentes de sistema en una arquitectura estándar \emph{QuickPath} de Intel.}
	\label{fig:quickpath}
\end{figure}

El esquema \emph{QuickPath} postula una reformación arquitectural de los componentes principales de un sistema \ref{fig:quickpath}. En éste esquema, las distintas unidades de procesamiento (CPU) están interconectadas por canales de comunicación especiales denominados \emph{Intel QuickPath Interconnect - QPI} que son conexiones punto a punto entre CPU de enorme velocidad de transferencia (llegando hasta 25 GB/s), los que junto con modificaciones al tradicional protocolo MESI, flexibiliza los protocolos de coherencia de caché dotando así de mayor eficiencia y velocidad de acción entre procesadores al ser una comunicación directa.
Por otro lado, en \emph{QuickPath} cada CPU dispone de su propio controlador de memoria y de un banco de memoria de acceso próximo. Dicho diseño se denomina un nodo \textbf{NUMA} de sus siglas en inglés \emph{\textbf{N}on \textbf{U}niform \textbf{M}emory \textbf{A}ccess} [CITA A NUMA] la que permite a las CPU de cada nodo NUMA disponer de un banco de memoria con un acceso garantizado más rápido que al que se tendría acceso en una arquitectura tradicional. El enfoque \emph{NUMA} se aprovecha del principio de localidad de memoria \cite{paper:memorylocality}, por la cual postula que los datos son separables en su acceso por las distintas CPU, logrando así mayor velocidad en el acceso a la memoria, y menor problemas de coherencia de la misma por modificaciones entre CPUs.

El diseño de Intel va más allá. Concientes de la necesidad de herramientas y utilidades para analizar la verdadera perfomance que provee ésta arquitectura, Intel provee unidades de monitoreo de perfomance (o \textbf{PMU}, por sus siglas en ingles \emph{\textbf{P}erformance} \textbf{M}onitoring \textbf{U}nit) que son componentes de hardware incorporado a los sistemas que permiten operaciones de inspección a nivel de comunicación entre componentes del sistema. A éste tipo de análisis se denomínan \emph{Estudios de Perfomance Counters}, dado que para poder realizar una medición, el fabricante de la PMU provee una colección de posibles eventos a colectar, con significaciones puntuales cada uno.

\begin{defn}[ver \cite{KAR00}] \textbf{Performance Counters} son identificadores de maquina que permiten cuantificar determinados eventos a nivel de hardware, como lecturas de caché, corrección de lineas de caché, comunicación de protocolos de coherencia, etc. Usados para analizar el comportamiento de ciertas unidades de hardware y que conforman la base de las herramientas de profiling para el rastreo en el comportamiento de funciones de un sistema.
\end{defn}
 
QPI imple,enta la wea de 5 capas!!!!! importante ponerlo!

El estudio de performance counters corresponde a uno de los estudios de más bajo nivel realizables en pos de obtener datos que representen la forma objetiva la comunicación entre componentes del sistema. Ello lo hace también un estudio dificultoso de realizar pues amerita un gran conocimiento de la arquitectura puntual sobre el sistema que se desea estudiar.

\subsection{Especificación y Captura de Eventos}
Para definir el marco conceptual de la prueba, se debe mantener presente el contexto de la hipótesis que fundamenta la misma. En éste caso, la motivación de éste estudio está en linea con entender el comportamiento de un comsumo concurrente en una estructura socket, o más precisamente, ver cómo una instancia de una primitiva de sincronización --un spinlock en este caso-- se comporta en un escenario multithread, dado que la misma podría alocarse en caches de distintos procesadores. En ese escenario, se busca estudiar cómo se manifestaría la expresión de los protocolos de coherencia de cache bajo circunstancias de ejecución en un escenario mutiprocesador que podrian dar cuenta de que el mal desempeño general del caso de estudio tiene sus origines en los mismos sistemas de coordinación de bajo nivel del sistema.

\subsubsection{Arquitectura de la máquina para las pruebas}
Siguiendo el caso de prueba evaluado a lo largo de la investigación, se inspeccionará el caso de estudio de saturación de un socket UDP en el equipo servidor multicore para pruebas (Ver fig. \ref{fig:hwspecs}). En éste caso, se cuenta con un equipo placa Dell Inc. 00NH4P A07, provisto de dos CPU Intel Xeon 5600 2.8Ghz, dotado de 6 cores cada uno. Cada CPU dispone de hasta tres niveles de cache de 192 kb, 1536kb y 12288kb respectivamente, que combinados con tres memorias de 4096MB (DDR3 1333MHz) cada uno, conforman 2 nodos NUMA, con un monto total de 24GB de memoria. Una configuración que es precisamente de la familia \emph{Intel QuickPath Architecture} y es enfocada a servidores multicpu \cite{report:intelxeon5600, manual:intelxeon5600}.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.7]{imagenes/arch24Cores.png}
	\caption{Esquema de arquitectura interna del esquipo servidor multicore sobre el que se realizan las pruebas de performance counters.}
	\label{fig:hwspecs}
\end{figure}

Al inspeccionar el sistema donde se evalúan las pruebas en detalle, se da cuenta de que para el modelo de procesador presente se dispone de 5 unidades de PMU disponibles, separables en 3 grupos (Ver código \ref{code:pmuavailable}):
\begin{description}
\item[PMU Genéricas] Incluyen a \verb=perf= y  \verb=perf_raw=. Disponen de las especificaciones estándar de perfomrance counters de la línea del software \emph{Perf}, lo cual las hace poco exactas en los valores descritos por cada evento y no necesariamente fieles a su descripción pues dependen en gran parte de que el fabricante sea riguroso en su implementación.
\item[PMU x86] PMU generacional de Intel para la línea x86 de Intel que incluye a \verb=ix86arch=. Dispone de eventos comunes a dicha linea de procesadores por lo que no da soporte especifico para la arquitectura \emph{quickPath} y del comportamiento multiprocesador.
\item[PMU westmere] PMU especificas de la línea Westmere [AKA UNA CITA] que soporta la base del desarrollo de la \emph{Intel QuickPath Architecture}, incluyendo a \verb=wsm_dp= y \verb=wsm_unc=. Es el nivel más exacto de PMU que provee el fabricante con los eventos más especificos y documentados del sistema.
\end{description}

\begin{lstlisting}[style=BashInputStyle, label={code:pmuavailable}, caption={Listado de \emph{PMUs} disponibles en el sistema, recuperado con la herramienta \emph{libpfm4}.}, captionpos=b]
	Detected PMU models:
[18, ix86arch, "Intel X86 architectural PMU", 6 events, 1 max encoding, 7 counters, core PMU]
[51, perf, "perf_events generic PMU", 104 events, 1 max encoding, 0 counters, OS generic PMU]
[53, wsm_dp, "Intel Westmere DP", 91 events, 2 max encoding, 7 counters, core PMU]
[54, wsm_unc, "Intel Westmere uncore", 52 events, 1 max encoding, 9 counters, uncore PMU]
[114, perf_raw, "perf_events raw PMU", 1 events, 1 max encoding, 0 counters, OS generic PMU]
\end{lstlisting}

\subsubsection{Metodología de captura de eventos}
Para la especificación de la captura de eventos, lo primero es prestar especial atención a la arquitectura interna en la comunicación interprocesador del sistema. En la figura \ref{fig:hwcomm} se da cuenta de los canales de comunicación que dispone el sistema estudiado.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.8]{imagenes/QuickPathChannels.png}
	\caption{Esquema de arquitectura interna del equipo servidor multicore estudiado, ilustrando las vías de comunicación del procesador que da cuenta de los principales puntos de alta comunicación en el escenario de \textit{cache bouncing} por contención de valores.}
	\label{fig:hwcomm}
\end{figure}

La figura \ref{fig:hwcomm} da cuenta de los puntos en que se pueden suceder escenarios de congestión dados ya sea por un alto nivel de uso de los protocolos de coordinación de memoria o por un alto tráfico de comunicación entre CPUs. Dichos canales de comunicación podemos resumirlos en las siguientes funciones dedicadas de la arquitectura estudiada, que a su vez están asociadas a ciertos Performance Counters del sistema:

\begin{itemize}
\item Uso de los canales \emph{Intel QuickPath QPI}
\item Acciones del protocolo \emph{SNOOP}
\item Pasos de datos entre distintos caché y memoria
\item Transiciones del protocolo \emph{MESI(F)}
\end{itemize}


Con ello en mente, se consultó el manual oficial del fabricante \cite{manual:bigbigevents} en búsqueda de documentación acerca de eventos disponible en el sistema que se relacionaran a las operaciones antes descritas. De dicha documentación, combinado con la utilidad \emph{libpfm4}\footnote{Corresponde a una utilidad confeccionada para recuperar información sobre los código de inspección de eventos de performance counters de un sistema.}\footnote{\url{http://www.bnikolic.co.uk/blog/hpc-prof-events.html}} para la recolección de eventos disponibles en el sistema se colectaron un total de 143 eventos, cada uno con hasta 6 variantes de configuración, dando en total casi 500 posibles eventos a estudiar. En este escenario es preciso acotar los eventos a considerar de acuerdo a los 4 criterios antes descritos.


[[[Hablar un poco de dicha busqueda y del manual]]]]

Finalmente, siguiendo los 4 criterios de puntos problemáticos a estudiar se construyó una selección de eventos a considerar resumida en la tabla \ref{table:eventos}. Los eventos están divididos en dos grupos: \textbf{QPI/GQ/Cache} para eventos relacionados con movimiento o traslación de datos entre distintas estructuras de hardware, y \textbf{LinkLayer} para eventos referidos a protocolos de consistencia y sincronización que son pertinenetes a la capa de corrección en el esquema de capas del \emph{Quickpath}.

\begin{table}[h!]
\centering
\begin{tabular}{l|l}
\multicolumn{1}{c|}{{\bf QPI/GQ/CACHE}} & \multicolumn{1}{c}{{\bf LinkLayer}} \\ \hline
{ UNC\_GQ\_DATA\_FROM} & SNOOPQ\_REQUESTS \\
{ UNC\_GQ\_DATA\_TO} & SNOOPQ\_REQUESTS\_OUTSTANDING \\
{ UNC\_QHL\_REQUESTS} & SNOOP\_RESPONSE \\
{ L1D} & UNC\_QPI\_RX\_NO\_PPT\_CREDIT \\
{ L2\_DATA\_RQSTS} & UNC\_QPI\_TX\_STALLED\_MULTI\_FLIT \\
{ UNC\_LLC\_HITS} & UNC\_QPI\_TX\_STALLED\_SINGLE\_FLIT \\
{ UNC\_LLC\_MISS} & UNC\_SNP\_RESP\_TO\_LOCAL\_HOME \\
{ UNC\_LLC\_LINES\_IN} & UNC\_SNP\_RESP\_TO\_REMOTE\_HOME \\
{ UNC\_LLC\_LINES\_OUT} & UNC\_IMC\_RETRY
\end{tabular}
\caption{Total de eventos inspeccionados y estudiados en el caso de estudio de consumo concurrente sobre sockets UDP.}
\label{table:eventos}
\end{table}

Con los eventos a colectar más claros, se confeccionó una utilidad para la obtención de los códigos de registros de cada evento de interés. Utilidad que operando en conjunto con \emph{libpfm4} es capaz de parsear datos del sistema para generar una colección de eventos (ver Tabla \ref{table:codigoseventos}) en formato \verb=JSON=\footnote{\url{https://github.com/sebablasko/libpfm4PerformanceEventParser}}. según los cuales se debería tener una correcta representación del nivel de saturación y uso de los componentes.

Con el \verb=JSON= generado, se pueden hacer mediciones de forma sencilla usando la herramienta \verb=stat= de \emph{Perf} para generar un reporte de la cantidad de veces que se registre actividad en el evento estudiado, especificado en la misma herramienta.

\begin{lstlisting}[style=BashInputStyle, breaklines=true, captionpos=b, caption={Ejemplo de uso de Perf para colectar datos de una colección de eventos sobre un script llamado programa. En éste caso se configura para colectar datos de 2 eventos y dejar el reporte de salida en un archivo resultado.txt}]
	# perf stat -e r53003c,r5300c0 -o resultado.txt -- ./programa
\end{lstlisting}

Finalmente, de los output de Perf, se pueden estudiar los resultados finales de la comunicación efectiva generada a lo largo de la prueba.

\begin{table}[]
\centering
\begin{tabular}{|l|l|p{0.58\linewidth}|}
\hline
Nivel de Inspección                 & Registro & Descripción                                                \\ \hline
\multirow{8}{*}{Uso de QPI}         & r500104  & Cycles GQ data is imported from Quickpath interface        \\ \cline{2-3} 
                                    & r500204  & Cycles GQ data is imported from Quickpath memory interface \\ \cline{2-3} 
                                    & r500404  & Cycles GQ data is imported from LLC                        \\ \cline{2-3} 
                                    & r500105  & Cycles GQ data sent to the QPI or QMC                      \\ \cline{2-3} 
                                    & r500205  & Cycles GQ data sent to LLC                                 \\ \cline{2-3} 
                                    & r500405  & Cycles GQ data sent to cores                               \\ \cline{2-3} 
                                    & r500420  & Quickpath Home Logic remote read requests                  \\ \cline{2-3} 
                                    & r500820  & Quickpath Home Logic remote write requests                 \\ \hline
\multirow{3}{*}{Snoop}              & r530451  & L1D cache lines replaced in M state                        \\ \cline{2-3} 
                                    & r530251  & L1D cache lines allocated in the M state                   \\ \cline{2-3} 
                                    & r530851  & L1D snoop eviction of cache lines in M state               \\ \hline
\multirow{15}{*}{Pasos entre Cache} & r500108  & Number of LLC read hits                                    \\ \cline{2-3} 
                                    & r500208  & Number of LLC write hits                                   \\ \cline{2-3} 
                                    & r500109  & Number of LLC read misses                                  \\ \cline{2-3} 
                                    & r500209  & Number of LLC write misses                                 \\ \cline{2-3} 
                                    & r50010a  & LLC lines allocated in M state                             \\ \cline{2-3} 
                                    & r50020a  & LLC lines allocated in E state                             \\ \cline{2-3} 
                                    & r50040a  & LLC lines allocated in S state                             \\ \cline{2-3} 
                                    & r50080a  & LLC lines allocated in F state                             \\ \cline{2-3} 
                                    & r500f0a  & LLC lines allocated                                        \\ \cline{2-3} 
                                    & r50010b  & LLC lines victimized in M state                            \\ \cline{2-3} 
                                    & r50020b  & LLC lines victimized in E state                            \\ \cline{2-3} 
                                    & r50040b  & LLC lines victimized in S state                            \\ \cline{2-3} 
                                    & r50080b  & LLC lines victimized in I state                            \\ \cline{2-3} 
                                    & r50100b  & LLC lines victimized in F state                            \\ \cline{2-3} 
                                    & r501f0b  & LLC lines victimized                                       \\ \hline
\multirow{4}{*}{MESI}               & r501f0b  & L2 data demand loads in E state                            \\ \cline{2-3} 
                                    & r530126  & L2 data demand loads in I state (misses)                   \\ \cline{2-3} 
                                    & r530326  & L2 data demand loads in M state                            \\ \cline{2-3} 
                                    & r530526  & L2 data demand loads in S state                            \\ \hline
\end{tabular}
\caption{Colección de eventos resumidos para la inspección de los canales de comunicación del sistema en escenarios multithread.}
\label{table:codigoseventos}
\end{table}

Para poder comprender mejor las tendencias de comportamiento de los distintos eventos en cada instancia de prueba con una determinada configuración de threads, se evaluaron 3 escenarios de consumo para visualizar sus resultados\footnote{AKA URL AL REPO QUE TIENE ESTA PRUEBA DE PERFCOUNTERS}:
\begin{enumerate}
\item Lectura concurrente desde un dispositivo virtual como \verb=dev_null=.
\item Lectura exclusiva desde un socket UDP.
\item Lectura concurrente desde un socket UDP.
\end{enumerate}

De esta manera, se busca tener un punto de comparación de qué fenómeno se manifiesta en escenarios de lectura concurrente sobre un socket que no se manifiesta en otros escenarios.

\subsection{Metodología de Experimentación}
Hablar de que se empleará el caso de estudiode la siguiente manera blablabla, haciendo enfasis en que la captura de eventos se hace a través del software perf y que se evalúan distintas configuraciones de threads, repitiendo el experimento una cantidad X de veces.
\begin{equation}
T_i = \left\{ T_{i,1},T_{i,2},T_{i,3}, \dots ,T_{i,59}, T_{i,60}\right\} 
\end{equation}

Finalmente, se construye con cada evento un set de registros que guardan un valor promedio para una evaluación de ciertos threads.

\begin{equation}
Event_j = \left(\overline{T_{1}}, \overline{T_{2}}, \overline{T_{4}}, \overline{T_{6}}, \overline{T_{8}}, \overline{T_{16}}, \overline{T_{24}}, \overline{T_{36}}, \overline{T_{48}}, \overline{T_{60}}\right)
\end{equation}

\subsection{Resultados}
AKA mostrar que se reconocen dos tendencias entre los grupos de eventos (sobre el caso de udp concurrente).


\subsubsection{Correlación de Eventos}
Para poder comprender mejor la tendencia de comportamiento en el experimento entre los distintos eventos capturados se repasaron posibles mecanismos de visualziación que permitieran una simple comparación entre dichas mediciones. Se optó por emplear una visualziación mediante el uso de una matriz de correlación\footnote{\url{https://en.wikipedia.org/wiki/Correlation_and_dependence#Correlation_matrices}}, de manera de poder detectar facilmente conjuntos de eventos relacionados, ello combinando algúna estratégia de clusterización en el proceso de visualizar los datos. Ésta técnica es muy práctica y se ha empleado en otros escenarios sobre el mismo kernel en otras investigaciones con buenos resultados \cite{paper:clusteringKernel}.

\begin{figure}[h!]
	\centering
	\hspace*{\fill}
	\subfigure[]{
		\includegraphics[width=.45\textwidth]{imagenes/corrgram0.png}
		\label{fig:corrgram:a}
	}\hfill
	\subfigure[]{
		\includegraphics[width=.45\textwidth]{imagenes/corrgram1.png}
		\label{fig:corrgram:b}
	}
	\caption{Resultado de la visualización de la matriz de correlación con el software \emph{statgraphics}. En la figura \ref{fig:corrgram:a} se pueden visualizar los datos en bruto, mientras en \ref{fig:corrgram:b} se presentan los datos agrupados, tras ordenar la matriz de acuerdo al criterio de los vectores propios, logrando un efecto clusterizador.}
	\label{fig:corrmatrix}
	\hspace*{\fill}
\end{figure}

Para ésta tarea, se empleó el software de visualización \emph{statgraphics}\footnote{\url{http://www.statgraphics.com/}} en su edición trial. El software tiene la capacidad de generar una visualización estupénda aprovechando un ordenamiento por medio del primer vector propio de la matriz de correlación misma, de manera de generar un efecto clusterizador sobre los datos, agrupando aquellos con alta correlación.

\subsection{Análisis y Discusión de Resultados}

\subsection{Conclusiones}
A raíz del estudio de canales de comunicación de hardware del sistema se pueden rescatar varios aspectos interesantes:
\begin{itemize}
\item Se identificó un comportamiento creciente en el registro de eventos capturados, trasversal entre todos los eventos postulados en el estudio.
\item La colección de eventos postulada en la tabla \ref{table:codigoseventos} de acuerdo con las componentes de la tabla \ref{table:eventos} registró 2 tendencias principales, una abarcando la gran mayoría de los eventos estudiados y otra, representativa de pocos eventos y de naturaleza exponencial.
\item Al observar en detalle la mayoría de los eventos, se da cuenta de cómo la tendencia de saturación sigue un régimen similar al de los tiempos generales del caso de estudio.
\end{itemize}

\section{Estudio de Distribución de Carga}
La tercera hipótesis de investigación plantea como responsable del mal rendimiento presentado en el caso de estudio al sistema de gestión y administración de tareas en el sistema operativo. En escenarios multicore como el estudiado es normal que el sistema operativo realice como procedimiento de rutina la migración de procesos y la re-alocación de recursos y datos para evitar la saturación de las componentes del mismo. Un caso práctico de ello es cuando un núcleo de procesamiento está sobreexigido y el sistema operativo redistribuye los hilos que están ejecutándose en dicho núcleo entre los otros procesadores disponibles del sistema con el costo que ello significa. Ésta práctica es conocida como \textbf{distribución de carga}, y a pesar de que existen varios mecanísmos de aprovechamiento de dicho esquema como una estratégia de balanceo de carga en arquitecturas como la estudiada \cite{paper:NUMA}, en ciertos escenarios puede degradar el desempeño general del sistema.

Ésta hipótesis plantea que dicho proceso de reasignación de recursos sería perjudicial en escenarios de concurrencia sobre arquitecturas como la estudiada, basandose en que mientras un proceso está en plena ejecución, al incorporar más y más tareas en el mismo nucleo de procesamiento agregando nuevos hilos de ejecución sería el sistema operativo quien comienzaría la reasignación automática de dichos hilos entre los distintos procesadores, cayendo en problemas como perdida de referencias de memoria en niveles de caché primario. En su peor escenario, ésta teoría lleva al ya mencionado problema de \emph{caché bouncing} \cite{paper:cachebouncing} que corresponde al fenómeno de sobre corrección de los datos a nivel de lineas de cache de un procesador, producido por constantes cambios de contexto del \emph{scheduller} que genera migración de procesos. Un problema que ya se mencionó en el estudio de la sección previa.

Una alternativa que se ha estudiado para solventar éste problema es la técnica de \emph{Processor Affinity} que consiste en la asociación de tareas o procesos en CPUs especificas, de manera de controlar la ubicación de memoria y zona real de ejecución del código en la máquina. En otras palabras, se remueve la utilidad del mismo scheduler del sistema operativo para coordinar la mejor operación en la asignación de los hilos de ejecución a las distintas CPU disponible, reemplazándolo por un criterio de diseño humano, construido concientes de la tarea que se desea realizar. Es una técnica muy ambiciosa en el sentido de que bien empleada puede proveer muy buenos resultados en el sistema \cite{paper:cacheaffinity}, sin embargo, es muy facil errar al interpretar el diseño de operación que se desea coordinar, llevando a una mala implementación en la asignación de recursos que termina degradando fuertemente el desempeño del sistema completo.

\begin{defn}[ver AKA AUN NO SE] \textbf{Processor Affinity} Y una bonita defiición de la wea
\end{defn}

En ésta tercer estudio se plantea la utilización de la técnica de \emph{Processor Affinity} en pos de conseguir un mejor rendimiento del caso de estudio presentado, por medio de la reasignación de los hilos de ejecución entre los distintos cores lógicos del sistema. Para evaluar ello, se plantean distintos esquemas de asignación de recursos basados en distintos argumentos arquitecturales del escenario de prueba y se evalúan comparativamente los resultados.


\subsection{Esquemas de Distribución}
Se diseñaron variados esquemas de asignación a fin de evaluar distintos enfoques de aprovechamiento del principio de localidad de memoria. En total se diseñaron 6 esquemas para evaluar combinaciones dinámicas de cores lógicos reconocidos por el sistema operativo en búsqueda de mejores rendimientos. Los esquemas se detallan a continuación:
\begin{description}
\item[SO] Asignación dinámica por scheduller del sistema operativo. En éste caso, la elección la hace el sistema de acuerdo a complejos argumentos de prioridad de proceso, carga de cpu, etc. Sirve como punto base de comparación con respecto a los demás esquemas.
\item[EquitativeAffinity] Asignación secuencial equitativa entre los cores lógicos del sistema, siguiendo la numeración que el sistema operativo dispone de los núcleos mismos. Supone que la distribución completamente justa y equitativa entre cores entrega un mejor rendimiento general.
\item[PairAffinity] Asignación secuencial de hilos a cores de numeración par. Búsca descartar explorar un escenario donde los cores duplicados por efecto de la tecnología \emph{hyperthreading} de Intel pudiera no aprovechar cores reales, y así generar un mejor desempeño final.
\item[DummyAffinity] Asignación directa de hilos a ejecución en el core 0 del sistema. Todos los hilos se delegan al mismo core. Bajo éste esquema se presume que se puede aprovechar mejor la localidad de memoria al disponer en el banco de memoria más próximo al núclo de ejecución todas las referencias necesirias, disminuyendo el efecto de sobrecarga de los protocolos de coherencia y coordinación de cache.
\item[NumaOddAffinity] Asignación de los hilos a cores del segundo conjunto NUMA disponible en el sistema. Sigue la idea de aprovechar toda una unidad lógica de procesamiento según la arquitectura \emph{Quickpath}, persiguiendo mejores tiempos al tener mejor acceso a memoria desde éstos cores.
\item[NumaEvenAffinity] Asignación de los hilos a cores del primer conjunto NUMA disponible en el sistema. Similar al argumento de \textbf{NumaOddAffinity}, pero usando el otro nodo NUMA disponible.
\end{description}

\subsection{Metodología de Experimentación}

\subsection{Resultados}

Aka muestro los resultados de todos los experimentos
\begin{figure}[!h]
	\centering
	\includegraphics[scale=.7]{imagenes/fcfm}
	\caption{Resultados experimentales de los affinitys.}
	\label{fig:resAffinity}
\end{figure}

\subsection{Análisis y Discusión de Resultados}
Aka hablar de como es un fiasco la utilización de processor affinity, seguramente porque el scheduller del sistema es mucho más inteligente en la asociación de tareas y threads a los distintos cores. Además la versión con processor affinity es rigida en la localidad del proceso con respecto al procesador lo cual hace que al tener sobrecarga de memoria, los niveles de caché no cooperen con la tarea general, y no brinden beneficio a la prueba final.

\subsection{Conclusiones}
A raíz del estudio de distribución de carga se pueden rescatar varios aspectos interesantes:
\begin{itemize}
\item Las técnicas de processor affinity degradaron aún más el rendimiento de consumo en el caso de estudio, con respecto al caso base de comparación.
\item Los distintos esquemas, a pesar de mostrar variaciones en cada caso, no lograron mejorar con respecto a los tiempos que brindó la administración del mismo sistema operativo.
\item Se vuelve a encontrar en el mismo socket una estructura que se vuelve un punto de contención, calificando al mismo como no apto para soportar accesos concurrentes, ello dado su diseño y mecanísmos de protección implementados (aka. el spinlock interno).
\end{itemize}

