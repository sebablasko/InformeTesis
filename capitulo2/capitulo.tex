\chapter{Estudio del Problema}

Como se mencionó al final del capítulo anterior, la investigación vigente del fenómeno estudiado en el presente trabajo ha concluido en generar distintas hipótesis para explicar el mal rendimiento presentado por los Internet sockets de Linux en escenarios de concurrencia, más sin corroborar la validez de ninguna hipótesis experimentalmente. Las sospechas responsables de dicho problema se pueden agrupar en tres aristas distintas: Problemas de operación en primitivas del sistema, problemas de operación a nivel de canales de comunicación de hardware y problemas de operación en los mecanismos de administración de recursos y balanceo de carga.

En el presente capítulo se estudian las tres líneas planteadas como potenciales responsables del problema, inspeccionando en distintos niveles y formas el funcionamiento del sistema, indagando en las operaciones teóricas de cada escenario y contrastando dicho planteamiento a los resultados experimentales obtenidos en cada caso. Es fruto de cada una de las siguientes subsecciones un análisis profundo del aspecto problemático estudiado junto con una conclusión sobre el mismo. Así también, es fruto del presente capítulo un veredicto sobre cuales -Y en qué medida- de los problemas estudiados tienen verdadera responsabilidad en el fenómeno estudiado, de modo de confeccionar un marco de trabajo que permita empezar a postular enfoques de soluciones que paleen la problemática en cuestión.

\section{Estudio de Operación Primitivas de sincronización del Sistema}

La primera hipótesis a estudiar plantea que el bajo rendimiento de la operación de la interfaz de red --Ilustrada en nuestro caso de estudio por medio de los Internet sockets UDP de Linux-- en escenarios de concurrencia, es causado por un mal desempeño de las estructuras que proveen los mecanismos de sincronización para dichos escenarios. Cómo se mencionó en el capítulo anterior, la capacidad multiprocesador de las computadoras modernas provee un mayor poder de cómputo que se postula a ser aprovechado por medio del uso de técnicas de programación paralela, con el cuidado de que en esos contextos de trabajo, los sistemas operativos deben estar preparados para atender situaciones de conflicto en el acceso a los recursos compartidos. Para éste propósito, los sistemas operativos proveen de mecanismos de sincronización ya repasados en secciones anteriores que para estructuras de bajo nivel --cómo los sockets de Internet-- emplean el uso de mecanismos de sincronización de bajo nivel como lo son los spinlocks, que protegen ciertas porciones críticas de la estructura, tal y como se repasó previamente.

En éste caso, la primera hipótesis del problema describe que el causante del mal rendimiento al incorporar concurrencia en las lecturas a un socket es generado derechamente por dichas estructuras de protección en el acceso simultaneo, situación que causaría el fenómeno denominado \emph{Contención de Recurso} sobre la estructura compartida, o sobre alguna de las componentes constitutivas de la misma.

\begin{defn}[ver \cite{paper:resourceContention}] \textbf{Contención de Recurso} corresponde a un estado de conflicto en el acceso a un recurso compartido entre distintas componentes de un sistema, producido por una situación de competencia en el acceso al mismo que puede degenerar en escenarios problemáticos como situaciones de bloqueo, conflictos por situaciones de carrera y degradación generalizada de performance, entre otros.
\end{defn}

Para ratificar el planteamiento anterior, se estudió la dinámica de llamadas de sistema presentes al momento de la ejecución experimental del caso del caso de estudio postulado en el capítulo anterior, ello siguiendo otros modelos de recopilación de datos ya evaluados en otros trabajos exitosos en la misma línea \cite{slides:hpPerf} a modo de poder modelar la operación de las primitivas de sincronización a medida que se van agregando hilos de procesamiento en el consumo de una misma estructura socket compartida. De la misma forma, es interesante analizar cómo el socket compartido actúa como un potencial punto de contención, o como alguna de las estructuras internas de limitación en su acceso (como sería el spinlock del socket mismo) tienen responsabilidad en el rendimiento presentado.

\subsection{Estudio de Llamadas de sistema}

La operación de las primitivas de sincronización que actúan en los procesos de bajo nivel del sistema operativo tienen la característica de estar determinadas por el uso de llamadas a funciones del sistema, ello pues es el mismo sistema operativo (o mejor dicho el núcleo del sistema) aquel que provee una interfaz simple para la invocar de dicha operación. Cómo son llamadas a funciones, es posible cuantificar cuándo y cómo se realizan las mismas pudiendo modelar el proceso completo por medio de éste mecanismo.

Cómo en nuestro caso de estudio interesa inspeccionar el comportamiento de primitivas de sincronización de bajo nivel como son los spinlocks, se debe contemplar la API con que trabaja el sistema para controlar éstas estructuras. Esto pues a pesar de que la estructura spinlock está definida unívocamente definida a nivel del núcleo de Linux, existen distintas funciones que proveen variantes en el funcionamiento de los spinlocks para operar en condiciones especiales, y dichos escenarios son presentables a lo largo de la ejecución del caso de prueba del estudio pudiendo impactar el rendimiento final. El objetivo de éste estudio concierne un análisis cuantitativo de la cantidad de llamadas a sistema que sean bloqueantes sobre estructuras bloqueantes de tipo spinlock y del tiempo que el sistema gasta en dichas condiciones.

En Linux los spinlocks se representan con estructuras \verb=spinlock_t= (incluidas en el archivo \verb= <linux/spinlock.h>=) que básicamente consisten en un campo de \emph{lock} con un valor 1 (si está libre) o 0 (si está ocupado). Existen diversas funciones de atención que aplican distintos tipos de bloqueo \cite{book:spinlocks}:

\begin{description}
\item[void spin\_lock\_init(spinlock\_t *lock);] Inicializa una estructura spinlock y setea su valor inicial de \emph{lock} en 1.
\item[void spin\_lock(spinlock\_t *lock);] Es el bloqueo básico del sistema para tomar el \emph{lock}. Consistente en la espera del \emph{lock} hasta que presente un valor igual 1 para luego setearlo en 0. Dicha espera se realiza con ciclos de \emph{busy-waiting} hasta que se brinde acceso. Es un bloqueo interrumpible por el sistema operativo, tanto por interrupciones de software como de hardware, dando paso a situaciones como que la CPU determine enviar el proceso responsable de la llamada a dormir por falta de recursos, memoria, etc.
\item[void spin\_lock\_irq(spinlock\_t *lock);] Bloqueo que deshabilita interrupciones del procesador local antes de adquirir el spinlock. Se debe cuidar de reactivar las interrupciones luego de liberado el \emph{lock}.
\item[void spin\_lock\_irqsave(spinlock\_t *lock, unsigned long flags);] Similar a la operación de \verb=spin_lock_irq=, pero con la diferencia de que almacena el estado de interrupción previo en el valor \verb=flags=, de manera de que puede restablecerlo fácilmente luego de liberar el \emph{lock}.
\item[void spin\_lock\_bh(spinlock\_t *lock)] Similar a \verb=spin_lock_irq= con la diferencia de que sólo deshabilita las interrupciones de software, manteniendo habilitadas las interrupciones por hardware del sistema.
\item[int spin\_trylock(spinlock\_t *lock);] Para operaciones no bloqueantes para el uso de spinlocks. Retorna cero en caso de fallo al obtener el lock. No deshabilita interrupciones.
\item[bool mutex\_spin\_on\_owner(struct mutex *lock, struct task\_struct *owner)] Bloqueo que opera sobre una estructura de exclusión mutua (\emph{mutex}) que utiliza el enfoque de \emph{Read-Copy-Update} (RCU), en donde los lectores son no bloqueantes. Ésta estructura tiene una sobrecarga menor que las anteriores; Sin embargo, las actualizaciones son más costosas ya que las versiones anteriores de la estructura de datos se deben guardar con el fin de dar cabida a los lectores ya existentes que se sincronizan a través de las barreras del \emph{mutex}. Utilizando el enfoque de la RCU el bloqueo con esta estructura \emph{mutex} asegura que la operación \emph{Test-and-Set} se ejecute en la misma CPU del propietario del \emph{lock}, lo que reduce la cantidad de comunicación de memoria caché (y por consiguiente, el efecto de contención).
\end{description}

Asociadas a las anteriores llamadas de sistema están las variantes \verb=*unlock*= que permiten liberar el elemento de bloqueo (seteando el valor del \emph{lock} de regreso a 1) para recuperar así su disponibilidad para otros procesos.

Para poder rescatar las llamadas a sistema existen distintas herramientas de software de bajo nivel, creados por los mismos desarrolladores del núcleo de Linux que permiten realizar la tarea que nos proponemos en éste caso.

\subsubsection{Perf}
Perf \cite{slides:perfTools} o también llamado \emph{Perf\_events\footnote{\url{https://perf.wiki.kernel.org/}}} es una herramienta de análisis de performance para entornos Linux. Corresponde a un subsistema del mismo kernel de Linux que provee un completo framework para el estudio de performance del sistema y de programas por medio de la captura de una amplia variedad de fuentes de datos. Perf es capaz de colectar datos por operatividad de software (contadores de software, \emph{tracepoints}, estadísticas de ejecución de funciones, paso a assembler, etc.) y también colectar información de control de hardware (manejo de PMU, lectura de \emph{performance counters}, etc.), características que lo postulan como uno de los sistemas más completos para las tareas de profilling de aplicaciones y sistemas y que lo hacen una herramienta indispensable para el actual estudio.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.45]{imagenes/perfArchitecture.png}
	\caption{Arquitectura de operación del framework provisto por \emph{Perf}.}
	\label{fig:perfFramework}
\end{figure}

Además de su gran capacidad para colectar datos, Perf es una herramienta de sencillo uso. Su funcionamiento se basa en la supervisión de un determinado proceso o tarea de la cual se construye un archivo con la información que se haya seleccionado a colectar \cite{article:perf}. Para ello, se pueden emplear las utilidades \verb=perf-record= y \verb=perf-stat= del framework las que trabajan supervisando un determinado proceso y proveyendo páginas de datos al espacio del kernel de Linux las cuales son escritas con información del sistema de dicho proceso, y son retornadas al espacio de usuario construyendo un informe a modo de output\footnote{La asignación del espacio de páginas a rellenar se hace por medio de la utilidad \verb=mmap= de Linux, que provee direcciones virtuales en un proceso para almacenar información.} (Ver figura \ref{fig:perfRecord}). Ésta característica es muy práctica pues sobre los reportes generados se pueden realizar operaciones de análisis más exhaustivos.

El potencial de ésta herramienta la perfila como una utilidad indispensable para el estudio en cuestión. En primer lugar por su capacidad de análisis de ejecución de código que permite obtener información cuantificada de las llamadas a sistema y de la dinámica del árbol de llamados\footnote{\emph{Call graph} en inglés, corresponde a un grafo dirigido que representa la relación de llamados entre las subrutinas constitutivas de un proceso principal.} que permite reconocer la naturaleza de las funciones involucradas en el caso de estudio. En segunda instancia Perf es una estupenda herramienta para la recolección de datos de hardware al aprovechar el uso de la \emph{Performance Monitoring Unit (PMU)} del hardware del sistema, una característica que será revisada en detalle en secciones posteriores.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.45]{imagenes/perfRecord.png}
	\caption{Esquema de captura de datos de un programa usando el comando \emph{perf-record}.}
	\label{fig:perfRecord}
\end{figure}

\subsubsection{FTrace}
FTrace\footnote{\url{http://elinux.org/Ftrace}} es otra poderosa herramienta para análisis de rendimiento de software disponible para sistemas Linux \cite{paper:FTraceSony}. Su funcionamiento opera de naturaleza muy íntima con respecto al kernel mismo pues su recolección de datos se basa en el rastreo de la ejecución de funciones de forma dinámica en el espacio de kernel, caracterizando los tiempos reales de permanencia de cada llamada. Característica que lo hace una estupenda utilidad para el estudio de llamadas al sistema pudiendo recuperar datos como el tiempo de ejecución y cantidad de ocurrencia de las mismas.

Para su uso, FTrace opera como un verdadero framework del sistema sobre el kernel, del cual se pueden usar distintos métodos de rastreo de llamadas. Una de las funciones más poderosas de FTrace es el resultado que se puede obtener por medio de la instrumentación de código, que se refiere a la práctica de incorporar a los programas a analizar \emph{tracepoints} --o puntos de rastreo-- que son declaraciones explicitas de secciones de código a analizar y registrar. A pesar de que ésta característica es muy cómoda para programas propios, en el caso del análisis de funciones y llamadas de sistema propias del kernel de Linux, la instrumentación de código es una característica dispensable, siendo sólo necesaria la precisión de qué llamadas a sistema considerar en el análisis pues FTrace es flexible para hacer análisis directamente de funciones del sistema. El uso de ésta herramienta es muy flexible y configurable siendo activable a disposición del usuario, otra característica muy importante pues, al hacer una operación de rastreo de bajo nivel en el sistema, la actividad de FTrace significa una leve degradación en los tiempos netos de actividad de ciertas características del sistema.

El provecho que se puede sacar de ésta herramienta es usar su capacidad para cuantificar tiempo de funciones del kernel de Linux para estudiar la atomicidad de las llamadas bloqueantes del sistema. Así por ejemplo, se pretende determinar el tiempo que se pasa en estados bloqueantes de spinlocks (que terminan siendo pasos de \emph{busy-waiting}) en los cuales sólo se pierde tiempo por efectos de contención de recursos.

\subsection{Metodología de Experimentación}

Dado que la naturaleza de éste estudio se relaciona con el comportamiento de funciones del sistema que administran las primitivas de acceso y sincronización de los Internet socket de Linux, se realizarán las configuraciones pertinentes para cada herramienta a fin de contemplar dichos puntos de análisis. En el caso de Perf, la recolección de datos se realizará con la herramienta \verb=perf-record= y se realiza un post-procesamiento sobre los archivos de reporte generado a fin de colectar los estadísticos asociados a las distintas funciones de manejo de spinlock antes mencionadas\footnote{Éste experimento correspondiente a la ejecución del proyecto \url{https://github.com/sebablasko/Test_MultiThreadStressTransmision} con privilegios de administrador.}.

Por otro lado, para el estudio con FTrace la configuración resulta un poco más compleja. Dado que es una herramienta de traceo dinámico que opera inspeccionando las llamadas de funciones de sistema, la activación de FTrace sobrecarga el funcionamiento del sistema general. Por ello, FTrace se debe activar y desactivar manualmente para analizar sólo los instantes de operación de la prueba de interés. Además, dado el amplio espectro de funciones disponibles para inspeccionar con el framework, se deben emplear las utilidades de filtrado de funciones a inspeccionar que provee el mismo framework, ello en pos de capturar funciones en línea con la dinámica del spinlock del Internet socket.

\vspace{1pc}
\begin{lstlisting}[style=BashInputStyle, label={code:ftrace}, caption={Configuración de filtros de FTrace sobre funciones a estudiar.}, captionpos=b]
[sebastian@labs-vhost ~]$ echo *spin* > /sys/kernel/debug/tracing/set_ftrace_filter 
[sebastian@labs-vhost ~]$ cat /sys/kernel/debug/tracing/set_ftrace_filter 
mutex_spin_on_owner
spin_msec
_spin_trylock
_spin_lock_irqsave
_spin_lock_irq
_spin_lock
_spin_unlock_irqrestore
_spin_lock_bh
_spin_trylock_bh
_spin_unlock_bh
bit_spin_lock
kvm_vcpu_on_spin
\end{lstlisting}

Por otra parte, el encendido y apagado del framework mismo se configuró como parte del script de experimentación en el programa de la prueba\footnote{\url{https://github.com/sebablasko/Test_UDPTrace/}}. En el mismo, se configuró la opción \verb=set_ftrace_pid= para explicitar la inspección de FTrace sólo sobre el programa de la prueba, además del uso de la utilidad \verb=trace_marker= para instrumentar porciones de código de la prueba (como creación de threads, y término de consumo de datos) que permitiese una mayor facilidad al momento de estudiar los logs de ejecución recuperados.


\subsection{Resultados}
A continuación se ilustran los resultados experimentales obtenidos correspondientes a los datos colectados por Perf y FTrace. A modo de validación estadística, los resultados de las pruebas contemplan el promedio de un rango de 60 repeticiones en cada configuración dada por el caso de estudio.

\subsubsection{Perf}
\begin{figure}[!h]
	\centering
	\includegraphics[scale=.6]{resultados/perfdetalle-crop.pdf}
	\caption{Resultados experimentales de los porcentajes de ejecución de las llamadas a sistema recolectadas por \emph{Perf}.}
	\label{fig:resPerf}
\end{figure}

\subsubsection{FTrace}
\begin{figure}[!h]
	\centering
	\includegraphics[scale=.6]{resultados/detalleFtrace-crop.pdf}
	\caption{Resultados experimentales de los tiempos de ejecución de las llamadas a sistema recolectadas por \emph{FTrace} para la adquisición y liberación del \emph{lock}.}
	\label{fig:detalleftrace}
\end{figure}


\subsection{Análisis y Discusión de Resultados}
A primera vista, los resultados corroboran una tendencia creciente de las operaciones (tanto en porcentaje como en tiempo neto de ejecución) de las operaciones de bloqueo sobre spinlock en las pruebas desarrolladas.

En el caso de los resultados de la prueba de Perf disponibles en la imagen \ref{fig:resPerf}, se puede apreciar un comportamiento dominante en el porcentaje de llamado de funciones de una de las funciones por sobre las demás: \textbf{\_spin\_lock\_bh}, llamada que en condiciones de concurrencia puede aumentar su porcentaje de presencia en la ejecución desde un 22\% a casi un 35\%. Otro punto interesante es que, a medida a medida que el escenario se vuelve más competitivo para los threads, los porcentajes rescatados por ésta prueba para llamadas de bloqueo aumentan hasta aproximadamente los 4 threads, desde donde se estabiliza, manteniéndose sobre el 40\% sólo en éste apartado.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.6]{resultados/sumaperf-crop.pdf}
	\caption{Gráfico de suma de porcentajes de llamadas de bloqueo del \emph{lock} de spinlock.}
	\label{fig:sumaperf}
\end{figure}

Para reconocer mejor la dinámica de consumo de tiempos en las funciones inspeccionadas en el caso de estudio, se usaron los reportes generados por Perf para construir un nuevo tipo de visualización de llamadas a sistema: Un \emph{Call-Graph-Chart} (Ver imagen \ref{fig:callgraph}), de manera de poder reconocer los bloques de funciones más repetidos en la ejecución del caso de prueba. Para ésta visualización se aprovechó el script \emph{gprof2dot}\footnote{\url{https://github.com/jrfonseca/gprof2dot}}. En éste caso, resulta evidente cómo el grafo de llamadas de sistema se complejiza drásticamente al incorporar más threads, de la mano con el aumento en los porcentajes de permanencia en llamadas de sincronización.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.5]{imagenes/fcfm}
	\caption{Visualización de call-graph identificando las llamadas a sistema y sus pesos en el caso de prueba.}
	\label{fig:callgraph}
\end{figure}

Lo anterior postula una primera relación entre el número de threads en el acceso concurrente al socket con respecto al porcentaje y dinámica de llamados a funciones de bloqueo del spinlock. Sin embargo, los porcentajes de llamadas no son del todo relevantes si no se saben los tiempos efectivos que significan en la prueba. Para ello, se repasan los resultados de Ftrace.

Los resultados generales obtenidos con el estudio de FTrace disponibles en la figura \ref{fig:detalleftrace} dan cuenta de un fenómeno aún más interesante. Al igual que con los datos colectados con Perf, se ilustra una estrecha relación entre los tiempos de operación de las funciones relacionadas a spinlock a medida que se van incorporando threads, sin embargo, en éste caso, la tendencia resulta siempre creciente, plasmando cómo a medida que se van usando más threads, el sistema operativo pasa más tiempo en tareas de coordinación en su acceso.

Por otro lado, al realizar una colección de datos con FTrace a modo de recuperar el total de tiempo que se pasa en operaciones de tipo de bloqueo de spinlock se obtiene el resultado ilustrado en la imagen \ref{fig:sumaFtrace}. Una característica interesante de éste resultado es que, la tendencia de tiempos producida tiene un ajuste de naturaleza logarítmica, con un índice de determinación superior al 96\%. Éste resultado es muy significativo, pues revela que los tiempos reales de acción de las funciones de bloqueo de spinlock siguen una tendencia de la misma naturaleza a los tiempos netos de operación del caso de estudio, estipulando una relación estrecha entre ambos y postulando como principal responsable de los tiempos finales a las funciones de coordinación en el acceso al spinlock.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.5]{resultados/sumaFtrace-crop.pdf}
	\caption{Tiempos totales de bloqueo sobre el \emph{lock} por las distintas llamadas de sistema capturadas por \emph{Ftrace} en el caso de estudio juntos con una curva de aproximación de tendencia.}
	\label{fig:sumaFtrace}
\end{figure}
Más aún, si se repasan las tendencias de cada una de las principales llamadas de bloqueo y de liberación de spinlock (ver figura \ref{fig:Ftracebloquealibera}) se puede ver como las tendencias de naturaleza logarítmica prevalecen al aumentar el número de threads en el consumo de datos. Sin perjuicio de lo anterior, otro dato interesante es que las operaciones de liberación (Fig. \ref{fig:ftracelibera}) son muchísimo más cortas que las de bloqueo (Fig. \ref{fig:ftracebloquea}) revelando el escenario de competencia al que se ve enfrentado el spinlock ante la concurrencia en el acceso.

\begin{figure}[h!]
	\centering
	\hspace*{\fill}
	\subfigure[Funciones de Bloqueo]{
		\includegraphics[width=.47\textwidth]{resultados/bloqueantesftrace-crop.pdf}
		\label{fig:ftracebloquea}
	}\hfill
	\subfigure[Funciones de Liberación]{
		\includegraphics[width=.47\textwidth]{resultados/liberadorasFtrace-crop.pdf}
		\label{fig:ftracelibera}
	}
	\caption{Graficos con tendencias de tiempos del lock capturados con \emph{Ftrace} a lo largo del caso de estudio.}
	\label{fig:Ftracebloquealibera}
	\hspace*{\fill}
\end{figure}

\subsubsection{TraceDisplay}
Para poder obtener una interpretación adicional del fenómeno reconocido, se construyó una herramienta de visualización de las llamadas a sistema para funciones de sincronización que permitiese reconocer las porciones de tiempo que tomasen en cada procesador dichas funciones. Para ello, la herramienta denominada \emph{TraceDisplay} recibe un log generado con \emph{FTrace} que incluya las llamadas de sistema ya filtradas, y construye un mapa de tiempo coloreado donde se pueden apreciar las porciones de tiempo que consume cada llamada y desde cual CPU se originan. El resultado se puede apreciar en la imagen \ref{fig:traceDisplay} donde se ilustra el caso de analizar los logs generados por FTrace en un escenario de acceso de 4 threads en el caso de estudio.

Éste subproducto de la investigación principal junto con su documentación de uso está publicado\footnote{Disponible en \url{https://github.com/sebablasko/TraceDisplay}} y disponible para su uso.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.34]{imagenes/traceVisualization.png}
	\caption{Visualización de aplicación de llamadas de sistema de sincronización realizadas entre procesadores, generada con la herramienta TraceDisplay.}
	\label{fig:traceDisplay}
\end{figure}

Resultados como el mostrado en la figura \ref{fig:traceDisplay} ilustran como en la práctica, las operaciones de bloqueo se terminan ejecutando secuencialmente, aun cuando son distintos los CPU que los originen. Esto producto de que es una misma estructura la que se está compartiendo la cual no tiene un soporte adecuado para permitir modificaciones concurrentes de orígenes distintos, generando así un sobrecosto producido por dicha serialización en el acceso.


\subsection{Conclusiones}
A raíz del estudio de operación de primitivas de sincronización del sistema se pueden rescatar varios aspectos interesantes:
\begin{itemize}
\item La tendencia en los costos de tiempo son crecientes a medida que se agregan hilos que consumen el mismo socket. Ello tanto en porcentaje de llamadas de sistema, como también en tiempos netos en dichas llamadas.
\item Se destacan estructuras de tipo spinlock como las más reiteradas en el rastro de llamadas a sistema para la aplicación de mecanísmos de protección en el caso de estudio. En particular, la llamada a sistema \textbf{\_spin\_lock\_bh} es la más significativa en la operación de los mecanismos de acceso y toma del \emph{lock} que protege al Internet socket.
\item Se reconoce una significativa diferencia entre los tiempos y porcentajes de llamadas a sistema de tipo bloqueante por sobre los de tipo liberador del \emph{lock}, escenario que da cuenta de la situación de competencia que empeora a medida que se incluyen más threads en la prueba.
\item Se destaca una tendencia de naturaleza logarítmica en el crecimiento de tiempos que toman las llamadas bloqueantes sobre el spinlock del socket, ajustada con un coeficiente de determinación superior al 96\% y que sigue la misma tendencia de los tiempos netos reconocidos en el caso de estudio.
\end{itemize}
A raíz de lo anterior, se reconoce en el spinlock de protección del socket como un punto de cuello de botella al momento de emplear accesos concurrentes a una estructura socket. Ello al actuar como un punto de bloqueo que termina serializando el acceso al consumo de datos y que, lejos de reducir los tiempos paralelizando el acceso, los aumenta, producto de la serialización y de la responsabilidad de coordinar los hilos, propios de éste escenario.


\section{Estudio de Canales de Comunicación de Hardware}
La segunda hipótesis para explicar la mala performance del caso de estudio presentado se centra en una arista relacionada hardware más que al software mismo. Cómo ya se mencionó, la capacidad multiprocesador de que se dispone en equipos modernos no es un recurso fácil de aprovechar, de hecho, se requiere de una sofisticada operación y diseño tanto de las aplicaciones que solicitan recursos como del sistema operativo que ha de administrarlos, para conseguir las anheladas mejoras de performance. Como se repasó en secciones anteriores, la capacidad de paralelismo viene dada gracias a un conjunto de protocolos y algoritmos de muy bajo nivel que coordinan y mantienen en estado coherente las distintas componentes de datos para los diferentes procesadores disponibles en un esquema \emph{SMP} \cite{paper:MESI, paper:snoop}, sin embargo, por muy sofisticados que dichos mecanismos sean, las nuevas tecnologías de hardware que prometen velocidades de trasferencia y acceso nunca antes imaginadas podrían significar un problema para dichas componentes, sobrepasándolas de cierta forma.

Es precisamente en ésta línea que se establece la segunda hipótesis. En éste caso, se adjudican las responsabilidades por el mal rendimiento presentado en el caso de estudio a un problema de contención de recursos (nuevamente relacionado al spinlock de los Internet sockets), pero ésta vez, asociado a la persistencia y disponibilidad que se da del mismo a través de los mecanismos de coordinación antes mencionados. En las arquitecturas modernas los protocolos \emph{MESI} y de \emph{SNOOP} son cruciales en la operación de ejecuciones paralelas para garantizar integridad en los datos, pero las arquitecturas modernas proponen nuevas distribuciones de los componentes internos de hardware, brindando canales de comunicación de mayor velocidad de transmisión y reasignando los recursos físicos en modos diferentes a los usados para la concepción de los mecanismos de control ya mencionados. Ésta hipótesis plantea la posibilidad de que el defecto de performance del caso de estudio sea generado por un fenómeno de \emph{Caché Bouncing}, producto del abusivo comportamiento de dichos mecanismos de control en las arquitecturas modernas.

\begin{defn}[ver \cite{paper:cachebouncing}] \textbf{Caché Bouncing} corresponde a un fenómeno producido en entornos multiprocesador, cuando distintas CPU realizan modificaciones a una línea de caché especifica que está siendo referenciada por varios procesadores. La modificación de la línea en cuestión se propaga de caché en caché según los protocolos de consistencia del sistema, pero cuando la cardinalidad de referencias de los distintos procesadores sobre la misma línea de caché es muy alta, los mecanismos de propagación de caché pueden operar deficientemente. Éste fenómeno impone una significativa carga en el bus de memoria y los distintos canales de comunicación afectados pudiendo degenerar desde una degradación del proceso responsable hasta una degradación generalizada de la performance del sistema.
\end{defn}

En ésta línea, el fenómeno de \emph{Cache Bouncing} se podría manifestar dada la arquitectura del sistema, la que al contemplar bancos de memoria diversos --algunos compartidos y otros exclusivos para los núcleos de procesamiento-- podría estar manifestándose como resultado de las modificaciones concurrentes de los distintos procesadores sobre la estructura socket compartida, y más precisamente sobre el spinlock de protección del socket. Lo anterior combinado a la operación de los protocolos de consistencia y correctitud para las líneas de caché del sistema postulan evidencia que hace perfectamente posible el diagnóstico de que se esté generando un escenario de sobrecarga de comunicación que termine degradando los tiempos totales de ejecución del caso de estudio.

Para validar la hipótesis anterior es preciso un cabal entendimiento de la arquitectura de hardware objetivo a fin de poder localizar puntos de contención y canales afectados. Junto con lo anterior, se hace crucial una comprensión significativa del funcionamiento de la \emph{Performance Monitoring Unit} que provee el fabricante, así como lograr configurarla y aprovecharla para la recolección de datos finales. En las siguientes secciones se realiza un estudio de la arquitectura descrita en la figura \ref{fig:pc3} del equipo sobre el cual se realizan las pruebas experimentales reales para poder acotar el dominio de estudio. Posteriormente se realiza un análisis experimental de las tendencias presentes en una tarea de acceso concurrente como la descrita en el caso de estudio de ésta investigación con el fin de corroborar o descartar las sospechas ya mencionadas del efecto de contención y \emph{caché bouncing} por eventos de performance de hardware.

\subsection{Características de Arquitecturas de Hardware Modernas}
Cómo ya se mencionó en secciones anteriores, los fabricantes de partes y piezas de computadoras están constantemente desarrollando importantes avances, de la mano con el desarrollo técnico de piezas que brinda mejores componentes de hardware cada día, y la línea de desarrollo de infraestructura de hardware principal de los computadores no está exenta de dicha evolución. En secciones anteriores se presentó como las arquitecturas han evolucionado desde el primer esquema \emph{SMP} propuesto con la distribución \emph{FSB}, pasando luego por nuevas configuraciones como \emph{DIB} y \emph{DHSI}, entre otras. Sin embargo, el desarrollo ha sido constante y hoy las arquitecturas han degenerado en esquemas bastante más complejos en pos de aprovechar al máximo la capacidad de los procesadores en la línea del paralelismo.

\subsubsection{Arquitectura Intel QuickPath}
El año 2008, el fabricante de procesadores Intel®\footnote{\url{http://www.intel.com/}} lanzó al mercado una nueva tecnología denominada \emph{Intel QuickPath Architecture} \cite{paper:quickpath} la que postuló un nuevo esquema organizacional de los componentes internos de la placa principal de las computadoras, así como también un nuevo esquema de conectividad entre los componentes de la misma, prometiendo entre otras cosas, un sistema más confiable, eficiente, rápido y escalable, que podría aprovechar mejor la capacidad de los múltiples procesadores de su misma línea. Rápidamente \emph{QuickPath} se posicionó en el mercado para competir con la tecnología \emph{HyperTransport} desarrollada por \emph{AMD}\footnote{Principal competidor de Intel en la industria de la manufactura de microprocesadores.}, abriendo paso definitivamente a una era, dejando atrás el enfoque \emph{FSB}.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.5]{imagenes/quickpath2.png}
	\caption{Diseño organizacional de los componentes de sistema en una arquitectura estándar \emph{QuickPath} de Intel.}
	\label{fig:quickpath}
\end{figure}

El esquema \emph{QuickPath} postula una reformación arquitectural de los componentes principales de un sistema \ref{fig:quickpath}. En ésta propuesta, las distintas unidades de procesamiento (CPU) están interconectadas por canales de comunicación especiales denominados \emph{Intel QuickPath Interconnect - QPI} que son conexiones punto a punto entre CPU de enorme velocidad de transferencia (llegando hasta 25 GB/s en canales con variantes unidireccional o bidireccional). En línea para aprovechar esta nueva arquitectura, Intel® propone una serie de modificaciones al tradicional protocolo MESI, construyendo el denóminado protocolo \textbf{MESIF} que es una evolución del primero, flexibilizando los protocolos de coherencia de caché al incorporar un nuevo estado para las lineas de caché (\textbf{F} - \emph{Forward}) dotando así de mayor eficiencia y velocidad de acción entre procesadores al ser una comunicación directa.

Por otro lado, en la arquitectura \emph{QuickPath} cada CPU dispone de su propio controlador de memoria y de un banco de memoria de acceso próximo. Dicho diseño se denomina un nodo \textbf{NUMA} de sus siglas en inglés \emph{\textbf{N}on \textbf{U}niform \textbf{M}emory \textbf{A}ccess} [CITA A NUMA] la que permite a las CPU de cada nodo NUMA disponer de un banco de memoria con un acceso garantizado más rápido que al que se tendría acceso en una arquitectura tradicional. El enfoque \emph{NUMA} se aprovecha del principio de localidad de memoria \cite{paper:memorylocality}, por la cual postula que los datos son separables en su acceso por las distintas CPU, logrando así mayor velocidad en el acceso a la memoria, y menor problemas de coherencia de la misma por modificaciones entre CPUs.

El trabajo de Intel® va más allá. Conscientes de la necesidad de herramientas y utilidades para analizar la verdadera performance que provee ésta arquitectura, Intel® provee unidades de monitoreo de performance embebidas en sus procesadores (o \textbf{PMU}, por sus siglas en ingles \emph{\textbf{P}erformance} \textbf{M}onitoring \textbf{U}nit) que son componentes de hardware incorporado a los sistemas que permiten la inspección de operaciones a nivel de comunicación entre componentes del sistema directamente. A éste tipo de análisis se denomina \emph{estudios de Perfomance Counters} dado que para poder realizar una medición, el fabricante de la PMU provee una colección de posibles eventos a colectar, con significaciones puntuales cada uno.

\begin{defn}[ver \cite{KAR00}] \textbf{Performance Counters} son identificadores de máquina que permiten cuantificar determinados eventos a nivel de hardware, como lecturas de caché, corrección de líneas de caché, comunicación de protocolos de coherencia, etc. Usados para analizar el comportamiento de ciertas unidades de hardware y que conforman la base de las herramientas de profiling moderno para el rastreo en el comportamiento de funciones de un sistema.
\end{defn}

La Intel® \emph{QuickPath Architecture} implementa un modelo de 5 capas (Ver fig. \ref{fig:5layersqpi}) para la comunicación de datos entre los núcleos de procesamiento (Similar al espíritu del modelo OSI). De dicho modelo, para la detección de comunicación de aplicaciones son muy significativos los niveles de: \textbf{Protocolo}, al asociar tareas del paso de paquetes, aplicación del protocolo MESIF y de los mecanismos de SNOOP para control y coherencia de líneas de caché, y \textbf{Link}, para el reconocimiento de mecanismos de corrección de errores y recuperación a lo largo de la transmisión de datos entre dispositivos, y para el llamado esquema de \emph{Crédito/Débito} desarrollado por el mismo fabricante que permite trasmisiones de datos confiables entre componentes.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.5]{imagenes/5layersqpi.png}
	\caption{Diagrama de las 5 capas implementadas en la Intel® \emph{QuickPath Architecture} ilustrando los niveles de control de distintas componentes y protocolos importantes del sistema.}
	\label{fig:5layersqpi}
\end{figure}

El estudio de \emph{performance counters} corresponde a uno de los análisis de más bajo nivel realizables en pos de obtener datos que representen la forma fiel la comunicación entre componentes del sistema. Ello lo hace también un estudio dificultoso de realizar pues amerita un gran conocimiento de la arquitectura puntual sobre el sistema que se desea estudiar, pero de enorme valor para valerse de información sobre la verdadera cuota de comunicación inherente a un caso de estudio.

\subsection{Especificación y Captura de Eventos}
Para definir el marco conceptual de la prueba, se debe mantener presente el contexto de la hipótesis que fundamenta la misma. En éste caso, la motivación de éste estudio está en línea con entender el comportamiento de un consumo concurrente en una estructura socket, o más precisamente, ver cómo una instancia de una primitiva de sincronización --un spinlock-- se comporta a nivel de actividad de hardware en un escenario multithread. En ese escenario, se busca estudiar cómo se manifestaría la expresión de los protocolos de coherencia de cache bajo circunstancias de ejecución en un escenario mutiprocesador que podrían dar cuenta de que el mal desempeño general del caso de estudio tiene sus origines en los mismos sistemas de coordinación de bajo nivel del sistema.

\subsubsection{Arquitectura de la máquina para las pruebas}
Siguiendo el caso de prueba evaluado a lo largo de la investigación, se inspeccionará el caso de estudio de saturación de un socket UDP en el equipo servidor multicore para pruebas (Ver fig. \ref{fig:hwspecs}). En éste caso, se cuenta con un equipo placa Dell Inc. 00NH4P A07, provisto de dos CPU Intel Xeon 5600 2.8Ghz, dotado de 6 cores cada uno. Cada CPU dispone de hasta tres niveles de cache de 192 kb, 1536kb y 12288kb respectivamente, que combinados con tres memorias de 4096MB (DDR3 1333MHz) cada uno, conforman 2 nodos NUMA, con un monto total de 24GB de memoria. Una configuración que es precisamente de la familia \emph{Intel QuickPath Architecture} y es enfocada a servidores multicpu \cite{report:intelxeon5600, manual:intelxeon5600}.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.7]{imagenes/arch24Cores.png}
	\caption{Esquema de arquitectura interna del esquipo servidor multicore sobre el que se realizan las pruebas de \emph{performance counters}.}
	\label{fig:hwspecs}
\end{figure}

Para inspeccionar el sistema donde se evalúan las pruebas en detalle en busca de componentes de monitoreo disponibles se utilizó la utilidad \emph{libpfm4}\footnote{\url{http://www.bnikolic.co.uk/blog/hpc-prof-events.html}} que corresponde a una herramienta confeccionada para recuperar información sobre los códigos de inspección de eventos de performance counters de un sistema y de las PMU disponibles en el mismo. De ello, se da cuenta de que para el modelo de procesador presente se dispone de 5 unidades de PMU disponibles, separables en 3 grupos (Ver código \ref{code:pmuavailable}):
\begin{description}
\item[PMU Genéricas] Incluyen a \verb=perf= y  \verb=perf_raw=. Disponen de las especificaciones estándar de \emph{performance counters} de la línea del software \emph{Perf}, lo cual las hace poco exactas en los valores descritos por cada evento y no necesariamente fieles a su especificación pues dependen en gran parte de que el fabricante sea riguroso en su implementación.
\item[PMU x86] PMU generacional de Intel para la línea x86 de Intel que incluye a \verb=ix86arch=. Dispone de eventos comunes a dicha línea de procesadores por lo que no da soporte específico para la arquitectura \emph{QuickPath} ni del funcionamiento multiprocesador.
\item[PMU westmere] PMU específicas de la línea Westmere [AKA UNA CITA] que soporta la base del desarrollo de la \emph{Intel QuickPath Architecture}, incluyendo a \verb=wsm_dp= y \verb=wsm_unc=. Es el nivel más exacto de PMU que provee el fabricante con los eventos más especificos y documentados del sistema, por lo que es la PMU más importante a la hora de colectar eventos.
\end{description}

\vspace{1pc}
\begin{lstlisting}[style=BashInputStyle, label={code:pmuavailable}, caption={Listado de \emph{PMUs} disponibles en el sistema, recuperado con la herramienta \emph{libpfm4}.}, captionpos=b]
	Detected PMU models:
[18, ix86arch, "Intel X86 architectural PMU", 6 events, 1 max encoding, 7 counters, core PMU]
[51, perf, "perf_events generic PMU", 104 events, 1 max encoding, 0 counters, OS generic PMU]
[53, wsm_dp, "Intel Westmere DP", 91 events, 2 max encoding, 7 counters, core PMU]
[54, wsm_unc, "Intel Westmere uncore", 52 events, 1 max encoding, 9 counters, uncore PMU]
[114, perf_raw, "perf_events raw PMU", 1 events, 1 max encoding, 0 counters, OS generic PMU]
\end{lstlisting}

\subsubsection{Metodología de captura de eventos}
Para la especificación de la captura de eventos, lo primero es prestar especial atención a la arquitectura interna en la comunicación interprocesador del sistema. En la figura \ref{fig:hwcomm} se da cuenta de los canales de comunicación que dispone el sistema estudiado, haciendo un acercamiento a cada unidad lógica de procesamiento, núcleo de cada nodo NUMA.

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.8]{imagenes/QuickPathChannels.png}
	\caption{Esquema de arquitectura interna del equipo servidor multicore estudiado, ilustrando las vías de comunicación del procesador que da cuenta de los principales puntos de alta comunicación en el escenario de \textit{cache bouncing} por contención de valores.}
	\label{fig:hwcomm}
\end{figure}

La figura \ref{fig:hwcomm} da cuenta de los distintos puntos en que se pueden suceder escenarios de congestión dados ya sea por un alto nivel de uso de los protocolos de coordinación de memoria o por un alto tráfico de comunicación entre CPUs. Dichos canales de comunicación podemos resumirlos en las siguientes funciones dedicadas de la arquitectura estudiada, que a su vez están asociadas a ciertos \emph{performance counters} del sistema:

\begin{itemize}
\item Uso de los canales \emph{Intel QuickPath QPI}
\item Acciones del protocolo \emph{SNOOP}
\item Pasos de datos entre distintos caché y memoria
\item Transiciones del protocolo \emph{MESI(F)}
\end{itemize}

Con ello en mente, se consultó el manual oficial del fabricante \cite{manual:bigbigevents} en búsqueda de documentación acerca de eventos disponible en el sistema que se relacionaran a las operaciones antes descritas. De dicha documentación, combinado con la utilidad \emph{libpfm4} para la recolección de eventos disponibles se colectaron un total de 143 eventos cada uno con hasta 6 variantes de configuración, dando en total casi 500 posibles eventos a estudiar. En este escenario es preciso acotar los eventos a considerar, de acuerdo a los 4 criterios antes descritos.


%[[[Hablar un poco de dicha busqueda y del manual]]]]

Finalmente, siguiendo los 4 criterios de puntos problemáticos a estudiar se construyó una selección de eventos a considerar resumida en la tabla \ref{table:eventos}. Los eventos están divididos en dos grupos: \textbf{QPI/GQ/Cache} para eventos relacionados con movimiento o traslación de datos entre distintas unidades de hardware, y \textbf{LinkLayer} para eventos referidos a protocolos de consistencia y sincronización que son pertinentes a la capa de corrección en el esquema de capas del \emph{Quickpath}.

\begin{table}[h!]
\centering
\begin{tabular}{l|l}
\multicolumn{1}{c|}{{\bf QPI/GQ/CACHE}} & \multicolumn{1}{c}{{\bf LinkLayer}} \\ \hline
{ UNC\_GQ\_DATA\_FROM} & SNOOPQ\_REQUESTS \\
{ UNC\_GQ\_DATA\_TO} & SNOOPQ\_REQUESTS\_OUTSTANDING \\
{ UNC\_QHL\_REQUESTS} & SNOOP\_RESPONSE \\
{ L1D} & UNC\_QPI\_RX\_NO\_PPT\_CREDIT \\
{ L2\_DATA\_RQSTS} & UNC\_QPI\_TX\_STALLED\_MULTI\_FLIT \\
{ UNC\_LLC\_HITS} & UNC\_QPI\_TX\_STALLED\_SINGLE\_FLIT \\
{ UNC\_LLC\_MISS} & UNC\_SNP\_RESP\_TO\_LOCAL\_HOME \\
{ UNC\_LLC\_LINES\_IN} & UNC\_SNP\_RESP\_TO\_REMOTE\_HOME \\
{ UNC\_LLC\_LINES\_OUT} & UNC\_IMC\_RETRY
\end{tabular}
\caption{Total de eventos inspeccionados y estudiados en el caso de estudio de consumo concurrente sobre sockets UDP.}
\label{table:eventos}
\end{table}

Con los eventos a colectar más claros, el siguiente paso consiste en conseguir los códigos de registro para la adquisición de cada evento. Un código de registro sigue una nomenclatura dada por el fabricante de la PMU y no guarda relación semántica con el valor que reporta, pero es la única referencia para indicar al software de recolección de datos el evento de interés a estudiar. Para ello, se confeccionó la herramienta \emph{libpfm4PerformanceEventParser}\footnote{\url{https://github.com/sebablasko/libpfm4PerformanceEventParser}} para la obtención de los códigos de registros de cada evento de interés, la cual trabajando en conjunto con \emph{libpfm4} es capaz de parsear datos del sistema para generar una colección de códigos de registro asociados a eventos de hardware en formato \verb=JSON=, según los cuales se debería tener una correcta representación del nivel de saturación y uso de los componentes.

Con el \verb=JSON= generado, se pueden hacer mediciones de forma sencilla usando la herramienta \verb=stat= de \emph{Perf} para generar un reporte de la cantidad de veces que se registre actividad en el evento estudiado, especificado en la misma herramienta.

\vspace{1pc}
\begin{lstlisting}[style=BashInputStyle, breaklines=true, captionpos=b, caption={Ejemplo de uso de Perf para colectar datos de una colección de eventos sobre un script llamado programa. En éste caso se configura para colectar datos de 2 eventos y dejar el reporte de salida en un archivo resultado.txt}]
	# perf stat -e r53003c,r5300c0 -o resultado.txt -- ./programa
\end{lstlisting}

Finalmente, de los output de Perf se pueden estudiar los resultados finales de la comunicación efectiva generada a lo largo de la prueba.

\subsection{Metodología de Experimentación}
Para poder comprender mejor las tendencias de comportamiento de los distintos eventos en cada instancia de prueba con una determinada configuración de threads, se confeccionó un experimento donde se evaluaron 3 escenarios de consumo para comparar sus resultados\footnote{\url{https://github.com/sebablasko/Test_PerformanceCounters}}:

\begin{enumerate}
\item Lectura concurrente desde un dispositivo virtual como \verb=dev_null=. Para ilustrar el caso de menor sobrecarga al ser un dispositivo libre de barreras de bloqueo aún con acceso concurrente.
\item Lectura exclusiva desde un socket UDP. En éste caso se consume la cuota definida en el caso de estudio por sockets con acceso exclusivo, distribuyendo la carga entre ellos con sólo 1 thread por socket. 
\item Lectura concurrente desde un socket UDP. Precisamente el caso de estudio evaluado a lo largo de toda la investigación.
\end{enumerate}

De esta manera, se busca tener un punto de comparación de qué fenómeno se manifiesta en escenarios de lectura concurrente sobre un socket, y que no se manifiesta en otros escenarios. Para la recolección de datos se optó por emplear nuevamente el software \emph{Perf} por su simple interfaz de manejo con la PMU del sistema. Al igual que en el caso de estudio original, se evalúan configuraciones de 1, 2, 4, 8, 16, 24, 36, 48, 64 y 128 threads, tras 60 repeticiones del proceso de captura para validez estadística. 

\begin{equation}
T_i = \left\{ T_{i,1},T_{i,2},T_{i,3}, \dots ,T_{i,59}, T_{i,60}\right\} 
\end{equation}

Finalmente, se construye con cada evento un set de registros que guardan un valor promedio para una evaluación de una determinada cantidad de threads.

\begin{equation}
Evento_j = \left(\overline{T_{1}}, \overline{T_{2}}, \overline{T_{4}}, \overline{T_{6}}, \overline{T_{8}}, \overline{T_{16}}, \overline{T_{24}}, \overline{T_{36}}, \overline{T_{48}}, \overline{T_{60}}\right)
\end{equation}

De ésta manera, se pueden hacer análisis más simples sobre las variables aleatorias $Evento_j$ que permita una simple comparación entre cada una de los 3 escenarios de evaluación estipulados.

\subsection{Resultados}
Dada la enorme cantidad de resultados obtenidos en el proceso de inspección de los \emph{performance counters}, se presentan sólo aquellos resultados con comportamiento interesante registrado en el caso de prueba.

Los resultados se han agrupado en 8 categorías para facilitar la asociación de comportamientos y de elementos analizados: Comportamiento de caché de datos de nivel 1, caché de nievl 2, último nivel de caché y banco de memoria, fallo en predicción de procesamiento, solicitudes fuera del core, comunicación por canales de la arquitectura \emph{Quickpath} y finalmente actividad de coordinación por protocolos \emph{SNOOP} y \emph{MESIF}.

\begin{figure}[ph!]
\centering
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r530151.png}
	\label{fig:pcounterL1a}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r530251.png}
	\label{fig:pcounterL1b}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r530451.png}
	\label{fig:pcounterL1c}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r530851.png}
	\label{fig:pcounterL1d}
}
\caption{Resultados asociados al comportamiento del caché de datos de primer nivel.}
\label{fig:pcounterL1}
\end{figure}

\begin{figure}[ph!]
\centering
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r530f28.png}
	\label{fig:pcounterMESIFa}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r530128.png}
	\label{fig:pcounterMESIFb}
}
\caption{Resultados asociados al comportamiento del protocolo MESIF.}
\label{fig:pcounterMESIF}
\end{figure}

\begin{figure}[ph!]
\centering
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r537f89.png}
	\label{fig:pcounterMissBranchPredictiona}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r5301c5.png}
	\label{fig:pcounterMissBranchPredictionb}
}
\caption{Resultados asociados al fenómeno de fallo en predicción de ejecución del procesador.}
\label{fig:pcounterMissBranchPrediction}
\end{figure}


\begin{figure}[ph!]
\centering
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r5301b0.png}
	\label{fig:pcounterOFFCorea}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r5380b0.png}
	\label{fig:pcounterOFFCoreb}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r530160.png}
	\label{fig:pcounterOFFCorec}
}
\caption{Resultados asociados al comportamiento de fallo en solicitud de datos de un core.}
\label{fig:pcounterOFFCore}
\end{figure}

\begin{figure}[ph!]
\centering
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r53aa24.png}
	\label{fig:pcounterL2a}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r53e027.png}
	\label{fig:pcounterL2b}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r530f26.png}
	\label{fig:pcounterL2c}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r5302f1.png}
	\label{fig:pcounterL2d}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r530127.png}
	\label{fig:pcounterL2e}
}
\caption{Resultados asociados al comportamiento del caché de segundo nivel.}
\label{fig:pcounterL2}
\end{figure}


\begin{figure}[ph!]
\centering
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r50010b.png}
	\label{fig:pcounterLLCa}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r50012e.png}
	\label{fig:pcounterLLCb}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r50022e.png}
	\label{fig:pcounterLLCc}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r500109.png}
	\label{fig:pcounterLLCd}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r500308.png}
	\label{fig:pcounterLLCe}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r530205.png}
	\label{fig:pcounterLLCf}
}
\caption{Resultados asociados al comportamiento del último nivel de caché y memoria principal.}
\label{fig:pcounterLLC}
\end{figure}


\begin{figure}[ph!]
\centering
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r500104.png}
	\label{fig:pcounterQPIa}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r500105.png}
	\label{fig:pcounterQPIb}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r500204.png}
	\label{fig:pcounterQPIc}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r500205.png}
	\label{fig:pcounterQPId}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r500240.png}
	\label{fig:pcounterQPIe}
}
\caption{Resultados asociados al comportamiento los canales y estructuras de comunicación del Intel® \emph{QuickPath}.}
\label{fig:pcounterQPI}
\end{figure}


\begin{figure}[ph!]
\centering
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r5301b4.png}
	\label{fig:pcounterSNOOPa}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r5302b4.png}
	\label{fig:pcounterSNOOPb}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r500106.png}
	\label{fig:pcounterSNOOPc}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r500107.png}
	\label{fig:pcounterSNOOPd}
}
\subfigure[]{
	\includegraphics[width=.47\textwidth]{resultados/pcounters/r500206.png}
	\label{fig:pcounterSNOOPe}
}
\caption{Resultados asociados al comportamiento del mecanísmo de control \emph{SNOOP}.}
\label{fig:pcounterSNOOP}
\end{figure}

\newpage

\subsection{Análisis y Discusión de Resultados}

Los diferentes resultados presentados en la sección anterior comparten una serie de características comunes importantes de resaltar: En primer lugar, la experimentación sobre el dispositivo virtual \verb=dev_null= presentó prácticamente un nulo registro a nivel de los eventos contabilizados. Una situación esperable pues como se adelantó al momento de diseñar el experimento, éste dispositivo fue elegido como parte de la prueba por ser un dispositivo virtual libre de protecciones ante concurrencia, de manera que su registro da pistas de la correcta activación de las labores de registro de eventos.

Otro rasgo general interesante es que los comportamientos entre el caso \emph{UDPMultiThread} y \emph{UDPSingleThreadMultiSocket} presentan notables diferencia en prácticamente todos los eventos inspeccionados en el caso de estudio, lo cual, más allá de los distintos valores registrados, corrobora que existe una significativa diferencia entre los dos enfoques de consumo de datos (compartición del socket con múltiples hilos contra consumo exclusivo de socket).

En las secciones siguientes se analizan en detalle cada uno de los grupos de resultados rescatados en ésta prueba.

\subsubsection{Comportamiento de caché de datos de nivel 1}
Los resultados registrados con respecto al comportamiento del caché de datos de nivel 1 (Ver figura \ref{fig:pcounterL1}) evidencian un claro comportamiento desigual entre los escenarios de consumo concurrente vs. consumo exclusivo. Como se aprecia en la mayoría de los resultados de dicha prueba, las tendencias entre ambos escenarios son similares hasta la aplicación de dos hilos, pero al incorporar más hilos de ejecución rápidamente los registros de eventos contabilizados se disparan en el caso multi-hilo, evidenciando una mayor actividad a nivel de caché de datos de nivel 1.

Otro dato interesante a resaltar es el fenómeno de \emph{caché bouncing} expresado en éste resultado. Cómo se puede apreciar, los resultados de las figuras \ref{fig:pcounterL1b}) y \ref{fig:pcounterL1c}) que expresan la cantidad de líneas de caché en estado modificado (de acuerdo a la nomenclatura \emph{MESI}) aumentan progresivamente a medida que se incrementan los hilos consumiendo datos del socket compartido, apoyando la idea de que el escenario concurrente contribuye a una mayor sobre corrección de líneas de caché, lo que puede contribuir en una degradación de la performance del sistema. Lo anterior es nuevamente avalado por el resultado de la figura \ref{fig:pcounterL1d}), que ilustra la acción de los protocolos de corrección y coordinación para modificar estados de líneas de caché. Vale decir, éste resultado muestra cómo los mecanismos de coordinación del sistema están operando desde componentes ajenas a cada Core para corregir líneas que han sido modificadas en otro procesador, otro indicio de que la modificación concurrente de una estructura compartida termina impactando al sistema completo.

Una última reflexión de éste resultado da cuenta de cómo las tendencias crecientes registradas por los eventos relacionados al caché de datos de nivel 1 se ajustan a la registrada por los tiempos prácticos de ejecución del caso de estudio, dando espacio para entender una correlación entre ambos fenómenos.

\subsubsection{Comportamiento de protocolo MESIF}
En el caso del protocolo MESIF, los resultados registrados a lo largo del caso de estudio (Ver figura \ref{fig:pcounterMESIF})) dan cuenta de dos situaciones a destacar relacionadas a los eventos detectados por concepto de escrituras de líneas de caché de nivel 1 a nivel 2, fenómeno que indica que un valor presente en ambos niveles de caché sufrió una modificación que hace que se propague hacia los niveles de caché inferiores.
La figura \ref{fig:pcounterMESIFa}) presenta el total de sobre escrituras realizadas desde el caché de datos de nivel 1 al caché de nivel 2. Es fácil notar que las tendencias dominantes nuevamente se atribuyen al escenario multi-hilo, que sobrepasa ampliamente al caso de lectura exclusiva desde un socket. Ésta situación respalda el escenario descrito en el análisis previo sobre el comportamiento de caché de datos de nivel 1, donde las sobre correcciones ocurridas en el sistema producto de la modificación de un recurso compartido termina aumentando excesivamente la comunicación práctica entre componentes. En el caso del resultado de la figura \ref{fig:pcounterMESIFb}) la situación resulta aún más dramática. 

En ese resultado se contabilizan los eventos de sobre escritura desde nivel 1 a nivel 2 sobre líneas que presentan estado \emph{Invalid} de acuerdo al protocolo \emph{MESI}, es decir, corrección de valores que ya fueron descartados por otro componente del sistema. Ésta situación da cuenta de cómo la coordinación a nivel de las líneas de caché se va tornando caótica a medida que se intensifican los escenarios concurrentes en el acceso al socket. Cabe destacar que tal como antes, las tendencias generales de los eventos registrados en el caso concurrente se adecúan mucho con la del tiempo del caso de estudio.

\subsubsection{Comportamiento de Predicción de ejecución del Procesador}
Una de las características fundamentales de los equipos modernos es la capacidad de anticipación de ciertas operaciones a realizar, ya sea cómputo de ciertos valores así como modificaciones o accesos a porciones de memoria. Para ello, durante la ejecución de un programa en que pueden continuar distintas secuencias de pasos, el sistema pre calcula el valor de algunos flujos a seguir de manera de anticiparse a dicho momento. Sin embargo, existen situaciones en que tal predicción resulta errónea con el costo de, primero, descartar los datos computados y, segundo, recalcular los valores necesarios. Tal escenario es denominado \emph{Branch Misprediction} y es justamente lo retratado por los resultados de la figura \ref{fig:pcounterMissBranchPrediction}).

Como se aprecia en los resultados, la cantidad de predicciones erróneas del sistema se dispara a medida que se incorporan hilos en el consumo de datos, escenario que necesariamente termina impactando los tiempos de operación y procesamiento finales. Siguiendo la tendencia de los valores recopilados por concepto de eventos muestreados, tanto los resultados de las figuras \ref{fig:pcounterMissBranchPredictiona}) como \ref{fig:pcounterMissBranchPredictionb}) siguen la misma tendencia de los tiempos finales, contribuyendo evidenciando más pistas de que la compartición del Internet socket termina degenerando el sistema.

\subsubsection{Comportamiento de fallo en solicitud de datos}
El resultado de la figura \ref{fig:pcounterOFFCore} refleja la dinámica de llamadas que realizan las distintas CPU solicitando datos que no disponen en sus bancos de memoria directos. Nuevamente el caso al usar múltiples hilos domina ampliamente sobre el escenario de lectura exclusiva.

El resultado de la figura \ref{fig:pcounterOFFCorea} ilustra el registro de solicitudes para leer datos en porciones ajenas al núcleo en cuestión. Es particularmente interesante que la tendencia frente al caso concurrente es muy similar al comportamiento detectado en el estudio de porcentajes de llamadas a funciones de bloqueo, abriendo la posibilidad de que dicha similitud se deba a que como el spinlock de protección del socket compartido sea una referencia cruzada entre todos los threads, su localización exacta varíe de momento en momento, haciendo necesario éste tipo de comunicación para dicha validación.

\subsubsection{Comportamiento de caché de nivel 2}
Similar al caso de los registros de caché de datos de nivel 1, el nivel 2 (Ver figura \ref{fig:pcounterL2}) presenta una dinámica de modificación que se acrecienta a medida que se incorporan más threads, siguiendo lo que ha sido la tónica de los demás resultados.

Un resultado particularmente interesante es el registrado en la figura \ref{fig:pcounterL2b} y \ref{fig:pcounterL2e} que hacen referencia a modificaciones en caché de nivel 2 de tipo \emph{RFO (Request For Ownership)}. Según dicta el protocolo MESI, una línea de caché sólo puede ser escrita si presenta un estado \textbf{M - Modificada} o \textbf{E - Exclusiva}. En caso de presentar un estado \textbf{S - Compartida} las copias deben ser invalidadas antes de la modificación, acción que se realiza por medio de las solicitudes \emph{RFO}. En éste resultado, se aprecia como claramente, las solicitudes de dicho tipo para modificación de líneas de caché en segundo nivel se desata frente al aumento de hilos consumiendo el mismo socket. Más evidencia para entender que, al tener un recurso compartido en distintas porciones del sistema, las modificaciones sobre el mismo se vuelven más significativas y perjudiciales al sistema completo.

\subsubsection{Comportamiento del último nivel de caché}
La dinámica del último nivel de memoria resulta la menos significativa en términos del impacto para con el caso de estudio, dado que es más inusual que se lleven a éste nivel las referencias que se postulan responsables del fenómeno estudiado. Sin embargo, los resultados de éste estudio presentes en la figura \ref{fig:pcounterLLC}) no dejan de ser interesantes.

Como ha sido tendencia en todos los resultados presentados, la compartición del socket entre diferentes hilos también impacta las referencias alocadas en éste nivel de datos, aunque sin seguir exactamente las mismas tendencias reconocidas a lo largo del estudio. Aun así, éstos resultados son importantes pues en éste nivel de memoria, la latencia en el acceso a los datos es la más significativa, lo que hace que un alto tráfico de la misma impacte en los tiempos finales también del caso de estudio.

\subsubsection{Comportamiento de los canales de comunicación propios de la arquitectura Intel® \emph{QuickPath}}

Los resultados de la figura \ref{fig:pcounterQPI} dan cuenta del nivel de comunicación de salida y entrada sobre los distintos nodos NUMA del sistema. En éste resultado se reconocen 3 tendencias principales:
\begin{itemize}
\item Figuras \ref{fig:pcounterQPIa} y \ref{fig:pcounterQPIc} que ilustran la cantidad de ocurrencias de importación de información, vale decir, el arribo de datos desde alguna porción externa al núcleo de procesamiento. En éste caso, las tendencias son similares a lo que ha marcado la tendencia general de los demás resultados, presentando una amplia dominación de los valores del caso concurrente.
\item Figura \ref{fig:pcounterQPIb}, que da cuenta de los niveles ce comunicación producidos por concepto de exportación de datos por los canales \emph{QuickPath} a otro nodo NUMA o a los bancos de memoria. En éste caso las tendencias son similares para los casos de acceso concurrente y para el acceso exclusivo hasta los 6 hilos de consumo. En escenarios de mayor concurrencia, el caso multi-hilo prosigue su aumento de eventos de exportación de datos mientras en el caso de accesos exclusivos, se comienzan a reducir. La tendencia en éste caso se repite con respecto a una curva de naturaleza logarítmica que se adecúa a los tiempos netos conseguidos en el caso de estudio.
\item Figuras \ref{fig:pcounterQPId} y \ref{fig:pcounterQPIe}. La primera ilustra la salida o exportación de datos desde el núcleo de procesamiento al último nivel de caché. La segunda se refiere al número de ciclos de procesamiento en que los canales QPI se estancan debido a falta de crédito en los protocolos de nivel de la capa Link de la arquitectura \emph{QuickPath}. Ambos con crecimientos muy significativos a medida que se incrementa el número de hilos y que se separan rápidamente de los registros en el escenario de acceso exclusivo al socket. Se debe prestar especial atención al resultado de la figura \ref{fig:pcounterQPIe} correspondiente a los ciclos de estancamiento pues, dicha situación da cuenta de que la interacción en los canales de comunicación está siendo tan intensa que está saturando los mismos, complicando la transmisión efectiva de datos a nivel de los canales de comunicación y cayendo en los denominados “ciclos muertos” por los mismos protocolos definidos para coordinar la comunicación en ésta arquitectura. Vale decir, es un síntoma de alta comunicación por los canales QPI.
\end{itemize}
En términos generales, los resultados de ésta sección siguen avalando el diagnóstico original de \emph{caché bouncing} por compartición del socket.

\subsubsection{Comportamiento de mecanismos de control del protocolo \emph{SNOOP}}
El último apartado de resultados presentado en la figura \ref{fig:pcounterSNOOP} corresponde a la interacción dada por los mecanismos de coordinación de caché del protocolo \emph{SNOOP}. A pesar de que en todos los escenarios, los registros de la prueba multi-hilo dominan por sobre los registrados en la prueba de acceso exclusivo, se visualizan dos comportamientos principalmente.

Los resultados de las figuras \ref{fig:pcounterSNOOPc}, \ref{fig:pcounterSNOOPd} y \ref{fig:pcounterSNOOPe} dan cuenta del uso de mecanismos de SNOOP para correcciones al último nivel de acuerdo a los cambios de estado del protocolo MESI. En éste caso, las tendencias son más variadas pero se preserva la situación de mando del caso multi-hilo en todos los resultados. Finalmente, los resultados de las figuras \ref{fig:pcounterSNOOPa} y \ref{fig:pcounterSNOOPb} dan cuenta de la cantidad de mensajes de solicitud de datos de líneas de caché o de marcación de invalidez de líneas de caché de niveles primario o secundario. Ambas tendencias son de crecimiento acelerado y de basto dominio en el caso concurrente. Nuevamente ésta situación avala el diagnóstico de \emph{caché bouncing} en el caso multithread.

\subsubsection{Correlación de Eventos}
Para poder comprender mejor la tendencia de comportamiento en el experimento entre los distintos eventos capturados se repasaron posibles mecanismos de visualziación que permitieran una simple comparación entre dichas mediciones. Se optó por emplear una visualziación mediante el uso de una matriz de correlación\footnote{\url{https://en.wikipedia.org/wiki/Correlation_and_dependence#Correlation_matrices}}, de manera de poder detectar facilmente conjuntos de eventos relacionados, ello combinando algúna estratégia de clusterización en el proceso de visualizar los datos. Ésta técnica es muy práctica y se ha empleado en otros escenarios sobre el mismo kernel en otras investigaciones con buenos resultados \cite{paper:clusteringKernel}.

Los eventos sobre los que se prestan especial atención son los relacionados a los criterios de selección antes explícitos, agrupados en la tabla \ref{table:eventos}, y cuya traducción a códigos de registro viene dada por la tabla \ref{table:codigoseventos}.

\begin{table}[]
\centering
\begin{tabular}{|l|l|p{0.58\linewidth}|}
\hline
Nivel de Inspección                 & Registro & Descripción                                                \\ \hline
\multirow{8}{*}{Uso de QPI}         & r500104  & Cycles GQ data is imported from Quickpath interface        \\ \cline{2-3} 
                                    & r500204  & Cycles GQ data is imported from Quickpath memory interface \\ \cline{2-3} 
                                    & r500404  & Cycles GQ data is imported from LLC                        \\ \cline{2-3} 
                                    & r500105  & Cycles GQ data sent to the QPI or QMC                      \\ \cline{2-3} 
                                    & r500205  & Cycles GQ data sent to LLC                                 \\ \cline{2-3} 
                                    & r500405  & Cycles GQ data sent to cores                               \\ \cline{2-3} 
                                    & r500420  & Quickpath Home Logic remote read requests                  \\ \cline{2-3} 
                                    & r500820  & Quickpath Home Logic remote write requests                 \\ \hline
\multirow{3}{*}{Snoop}              & r530451  & L1D cache lines replaced in M state                        \\ \cline{2-3} 
                                    & r530251  & L1D cache lines allocated in the M state                   \\ \cline{2-3} 
                                    & r530851  & L1D snoop eviction of cache lines in M state               \\ \hline
\multirow{15}{*}{Pasos entre Cache} & r500108  & Number of LLC read hits                                    \\ \cline{2-3} 
                                    & r500208  & Number of LLC write hits                                   \\ \cline{2-3} 
                                    & r500109  & Number of LLC read misses                                  \\ \cline{2-3} 
                                    & r500209  & Number of LLC write misses                                 \\ \cline{2-3} 
                                    & r50010a  & LLC lines allocated in M state                             \\ \cline{2-3} 
                                    & r50020a  & LLC lines allocated in E state                             \\ \cline{2-3} 
                                    & r50040a  & LLC lines allocated in S state                             \\ \cline{2-3} 
                                    & r50080a  & LLC lines allocated in F state                             \\ \cline{2-3} 
                                    & r500f0a  & LLC lines allocated                                        \\ \cline{2-3} 
                                    & r50010b  & LLC lines victimized in M state                            \\ \cline{2-3} 
                                    & r50020b  & LLC lines victimized in E state                            \\ \cline{2-3} 
                                    & r50040b  & LLC lines victimized in S state                            \\ \cline{2-3} 
                                    & r50080b  & LLC lines victimized in I state                            \\ \cline{2-3} 
                                    & r50100b  & LLC lines victimized in F state                            \\ \cline{2-3} 
                                    & r501f0b  & LLC lines victimized                                       \\ \hline
\multirow{4}{*}{MESI}               & r501f0b  & L2 data demand loads in E state                            \\ \cline{2-3} 
                                    & r530126  & L2 data demand loads in I state (misses)                   \\ \cline{2-3} 
                                    & r530326  & L2 data demand loads in M state                            \\ \cline{2-3} 
                                    & r530526  & L2 data demand loads in S state                            \\ \hline
\end{tabular}
\caption{Colección de eventos resumidos para la inspección de los canales de comunicación del sistema en escenarios multithread.}
\label{table:codigoseventos}
\end{table}

\begin{figure}[h!]
	\centering
	\hspace*{\fill}
	\subfigure[]{
		\includegraphics[width=.45\textwidth]{imagenes/corrgram0.png}
		\label{fig:corrgram:a}
	}\hfill
	\subfigure[]{
		\includegraphics[width=.45\textwidth]{imagenes/corrgram1.png}
		\label{fig:corrgram:b}
	}
	\caption{Resultado de la visualización de la matriz de correlación con el software \emph{statgraphics}. En la figura \ref{fig:corrgram:a} se pueden visualizar los datos en bruto, mientras en \ref{fig:corrgram:b} se presentan los datos agrupados, tras ordenar la matriz de acuerdo al criterio de los vectores propios, logrando un efecto clusterizador.}
	\label{fig:corrmatrix}
	\hspace*{\fill}
\end{figure}


Para ésta tarea, se empleó el software de visualización \emph{statgraphics}\footnote{\url{http://www.statgraphics.com/}}. El software tiene la capacidad de generar una visualización estupénda aprovechando un ordenamiento por medio del primer vector propio de la matriz de correlación misma, de manera de generar un efecto clusterizador sobre los datos, agrupando aquellos con alta correlación.

Como se puede apreciar en su resultado, la vasta mayoría de los eventos estudiados en la matriz de correlación presentan un enorme grado de similitud en sus tendencias (Próximos a 1), lo que combinado con los resultados anteriores de las curvas de registro colectadas con el estudio de \emph{performance counters} da que el grueso de los registros de eventos colectados sigue la misma tendencia de crecimiento del tiempo registrado por el caso de estudio, lo que contribuye nueva evidencia de que el conjunto de mecanismos de comunicación verificables por ésta vía está comprometida por efecto del acceso concurrente a una estructura única.

\subsection{Conclusiones}
A raíz del estudio de canales de comunicación de hardware del sistema se pueden rescatar varios aspectos interesantes:
\begin{itemize}
\item Se identificó un comportamiento creciente en el registro de eventos capturados, trasversal entre todos los eventos postulados en el estudio.
\item Se recabó evidencia de distintos niveles de comunicación cómo transferencia de valores entre niveles de caché y memoria, en conjunto con la actividad de los protocolos de coherencia y corrección de líneas de caché que apoya la hipótesis del escenario de \emph{caché bouncing} en el sistema estudiado.
\item se determinó experimentalmente que bajo el régimen de acceso concurrente a un mismo socket, se evidencian más problemas reflejados en el aumento de predicciones erróneas de los procesadores y de grandes aumentos en los canales de comunicación de datos entre componentes de procesamiento, evidencia que respalda la sospecha de la existencia de una estructura (el spinlock del socket) altamente compartida y requerida por los distintos cores, situación que degenera en degradaciones importantes del sistema.
\item Al observar en detalle la mayoría de los eventos, se da cuenta de cómo la tendencia de saturación sigue un régimen similar al de los tiempos generales del caso de estudio.
\item La colección de eventos correlacionados evidenció una tendencia generalizada y uniforme sobre los eventos involucrados, los cuales además de estar fuertemente correlacionados entre sí, siguen la misma tendencia de los tiempos del caso de estudio.
\end{itemize}


\section{Estudio de Distribución de Carga}
La tercera hipótesis de investigación plantea como responsable del mal rendimiento presentado en el caso de estudio al sistema de gestión y administración de tareas en el sistema operativo. En escenarios multicore como el estudiado, es normal que el sistema operativo realice como procedimiento de rutina la migración de procesos y la re-locación de recursos y datos para evitar la saturación de las componentes del mismo. Un caso práctico de ello es cuando un núcleo de procesamiento está sobre exigido y el sistema operativo redistribuye los procesos que están ejecutándose en dicho núcleo entre los otros procesadores disponibles del sistema con el costo que ello significa. Ésta práctica es conocida como \textbf{distribución de carga}, y a pesar de que existen varios mecanismos de aprovechamiento de dicho esquema como una estrategia de balanceo de carga en arquitecturas como la estudiada \cite{paper:NUMA}, en ciertos escenarios puede degradar el desempeño general del sistema.

Ésta hipótesis plantea que dicho proceso de reasignación de recursos sería perjudicial en escenarios de concurrencia sobre arquitecturas como la estudiada, basándose en que mientras un proceso está en plena ejecución, al incorporar más y más tareas en el mismo núcleo de procesamiento agregando nuevos hilos de ejecución, sería el sistema operativo quien comenzaría la reasignación automática de dichos hilos entre los distintos procesadores cayendo en problemas como perdida de referencias de memoria en niveles de caché primario, yendo así en contra del principio de localidad de acceso a la memoria. En su peor escenario, ésta teoría lleva al ya mencionado problema de \emph{caché bouncing} que corresponde al fenómeno de sobre corrección de los datos a nivel de líneas de cache de un procesador, producido por constantes cambios de contexto del \emph{scheduller} que genera migración de procesos. Un problema que ya se mencionó en el estudio de la sección previa.

Una alternativa que se ha estudiado para solventar éste problema es la técnica de \emph{Processor Affinity} que consiste en la asociación de tareas o procesos en CPUs específicas, de manera de controlar la ubicación de memoria y zona real de ejecución del código en la máquina.
\begin{defn}[ver \cite{article:processoraffinity}] \textbf{Processor Affinity} es una estrategia de trabajo que consiste en la asociación de ciertos procesos o hilos de trabajo con determinados núcleos de procesamiento lógicos de un sistema. Dicha asociación restringe la capacidad de ejecución del hilo o proceso exclusivamente a su núcleo de procesamiento asignado.
\end{defn}
En otras palabras, con la aplicación de \emph{processor affinity} se remueve la utilidad del mismo scheduler del sistema operativo para coordinar la mejor operación en la asignación de los hilos de ejecución a las distintas CPU disponible, reemplazándolo por un criterio de diseño humano construido consientes de la tarea que se desea realizar. Es una técnica muy ambiciosa en el sentido de que bien empleada puede proveer muy buenos resultados en el sistema \cite{paper:cacheaffinity}, sin embargo, es muy fácil errar al interpretar el diseño de operación que se desea coordinar, llevando a una mala implementación en la asignación de recursos que termina degradando fuertemente el desempeño del sistema completo.

En ésta tercer estudio se plantea la utilización de la técnica de \emph{Processor Affinity} en pos de conseguir un mejor rendimiento del caso de estudio presentado, ello por medio de la reasignación de los hilos de ejecución entre los distintos cores lógicos del sistema en pos de explotar mejor la localidad de recursos en una arquitectura como la que se dispone. Para evaluar lo anterior, se plantean distintos esquemas de asignación de recursos basados en argumentos arquitecturales del escenario de prueba y se evalúan comparativamente los resultados.

\subsection{Esquemas de Distribución}
Se diseñaron variados esquemas de asignación a fin de evaluar distintos enfoques de aprovechamiento del principio de localidad de memoria. En total se diseñaron 6 esquemas para evaluar combinaciones dinámicas de cores lógicos reconocidos por el sistema operativo en búsqueda de mejores rendimientos. Los esquemas se detallan a continuación:
\begin{description}
\item[Sin Processor Affinity] Asignación dinámica por el scheduller del sistema operativo. En éste caso, la elección la hace el sistema de acuerdo a complejos algoritmos que consideran prioridad de proceso, carga de CPU, entre otros. Sirve como punto base de comparación con respecto a los demás esquemas.
\item[DummyAffinity] Asignación directa de hilos a ejecución en el core 0 del sistema, así, todos los hilos se delegan al mismo core. Bajo éste esquema se presume que se puede aprovechar mejor la localidad de memoria al disponer en el banco de memoria más próximo al núcleo de ejecución todas las referencias necesarias, disminuyendo el efecto de sobrecarga de los protocolos de coherencia y coordinación de cache.
\item[EquitativeAffinity] Asignación secuencial equitativa entre los cores lógicos del sistema siguiendo la numeración que el sistema operativo dispone de los núcleos mismos. Supone que la distribución completamente justa y equitativa entre cores entrega un mejor rendimiento general al reducir la carga de procesamiento de cada core.
\item[PairAffinity] Asignación secuencial de hilos a cores de numeración par. Busca descartar un escenario donde los cores duplicados por efecto de la tecnología \emph{hyperthreading} de Intel pudieran no aprovechar cores reales, generando así un mejor desempeño final.
\item[ImpairAffinity] Asignación secuencial de hilos a cores de numeración impar. Similar al anterior variando los cores elegidos.
\item[NumaPairAffinity] Asignación de los hilos a cores del segundo conjunto NUMA disponible en el sistema. Sigue la idea de aprovechar toda una unidad lógica de procesamiento según la arquitectura \emph{Quickpath}, persiguiendo mejores tiempos al tener mejor acceso a memoria desde éstos cores.
\item[SimpleCoreAffinity] Asignación de los hilos a los primetos dos cores lógicos del sistema, correspondientes al primer core real duplicado por efecto \emph{HyperThreading}.
\end{description}

\subsection{Metodología de Experimentación}
Para evaluar los distintos esquemas de afinidad ya postulados, se modificó el caso de estudio para incorporar la asociación de hilos de ejecución para con los distintos cores del sistema. Para ello se aprovechó la flexibilidad de la librería \emph{PThreads}, responsable de brindar los hilos de ejecución en nuestro caso, para usar ciertas llamadas a sistema que nos otorgasen el control de la localidad de ejecución buscada. En concreto, se empleó la función \verb=pthread_attr_setaffinity_np()= que permite especificar precisamente la asociación de un hilo para con el core de ejecución deseado. 

La prueba anterior se recopiló en un nuevo experimento\footnote{\url{https://github.com/sebablasko/Test_DifferentAffinityThreadsBySocket}} que, para efectos de validez estadística, se ejecutó un total de 60 veces, y se rescataron los valores promedios de dichas ejecuciones.

\subsection{Resultados}

\begin{figure}[!h]
	\centering
	\includegraphics[scale=.6]{resultados/processoraffinity-crop.pdf}
	\caption{Resultados experimentales de los distintos esquemas de afinidad.}
	\label{fig:resAffinity}
\end{figure}

\subsection{Análisis y Discusión de Resultados}
Los resultados experimentales ilustrados en la imagen \ref{fig:resAffinity} son diversos y poco alentadores. En efecto, ningún esquema de distribución evaluado consiguió reducir verdaderamente el tiempo de ejecución al usar una configuración trivial de un único thread, sin embargo, los resultados obtenidos reflejan distintas tendencias en los tiempos resultantes del experimento.

Una primera tendencia evidenciada en los resultados viene dado por los esquemas \textbf{DummyAffinity} y \textbf{SimpleCoreAffinity}, donde los tiempos se mantuvieron estables a lo largo de la evaluación de las distintas configuraciones de threads. Si recordamos, ambos esquemas son rígidos en la posibilidad de locación de los hilos en la CPU, el primero los asigna todos al core \#0 mientras que el segundo los asigna todos entre el core \#0 y el core \#12, numeración que da el sistema operativo a los núcleos duplicados por efecto de la tecnología \emph{HyperThreading}. De ésta manera, ambos esquemas tienen en común que ejecutan la totalidad de los hilos en un mismo núcleo real de procesamiento. Ahora bien, ninguno de los dos consigue ganancias efectivas de tiempo con respecto al uso de un único thread, ello se explica pues, dado que los distintos hilos son asignados todos a un mismo core, la ejecución de los mismos termina degenrando a una ejecución secuencial, es decir, por medio de la afinidad de proceso hemos eliminado la capacidad de paralelismo al llevar el experimento a un escenario monocore. Esto explica también el por qué los tiempos son tan uniformes sin importar la cantidad de hilos que se usen.

Una segunda tendencia reconocible es la ilustrada por el esquema \textbf{EquitativeAffinity}. Resultante como el de peor desempeño, éste esquema que se caracterizaba por la distribución justa de los hilos entre los cores registra siempre los peores tiempos de la prueba. Ésta tendencia se explica por la naturaleza de la arquitectura que se está usando. Como se mencionó antes, la distribución del sistema corresponde a dos nodos NUMA de procesamiento. La aplicación del esquema equitativo vulnera derechamente tanto los beneficios que provee el esquema NUMA como el principio mismo de localidad en acceso a la memoria, ello pues en la práctica, termina distribuyendo los distintos hilos en las componentes más alejadas (topológicamente) de la arquitectura disponible.

Finalmente, una tercera tendencia es la de crecimiento producido por el conjunto de los demás esquemas de afinidad. La similitud entre \textbf{PairAffinity} e \textbf{ImpairAffinity} era previsible pues el modelo de distribución era equivalente para ambos. La misma naturaleza sigue el esquema \textbf{NumaPairAffinity} que, a pesar de aprovechar la distribución de componentes para la localización de hilos, no consiguió mejores tiempos que los ya representados. Ahora bien, hay que destacar que en términos prácticos, éste último grupo de esquemas de distribución tuvo un rendimiento muy similar al del mismísimo scheduller del sistema operativo, más aún, con la técnica de \emph{processor affinity}, la ejecución del programa es rígida en la localidad del proceso con respecto al procesador seleccionado, lo cual produce que en ciertas situaciones --como al tener sobrecarga de memoria-- los niveles de caché no cooperen con la tarea general, y no brinden mayor beneficio a la prueba final, una garantía que si dispone el scheduller del sistema operativo, por lo tanto su desempeño no debe ser menospreciado y sólo da cuenta de que lamentablemente, el problema de rendimiento parece ser producto de un defecto de diseño inherente a la estructura que se está compartiendo, defecto que no permite optar a mejores tiempos sin importar la estrategia de paralelismo usada.


\subsection{Conclusiones}
A raíz del estudio de distribución de carga se pueden rescatar varios aspectos interesantes:
\begin{itemize}
\item Las técnicas de \emph{processor affinity} empleadas no consiguieron beneficio alguno en el rendimiento de consumo del caso de estudio, ello a pesar de evaluar distintos esquemas en pos de sacar provecho de la arquitectura evaluada.
\item Los distintos esquemas, a pesar de ser rígidos en la ejecución de hilos sobre ciertos cores, fueron competitivos con respecto a la capacidad dinámica del scheduller del sistema operativo en los tiempos producidos en el experimento.
\item Se determina que es el mismo socket –o alguna componente inherente de sincronización como su spinlock-- una estructura que se vuelve un punto de contención al emplear hilos paralelos, calificando al mismo como no apto para soportar accesos concurrentes, ello dado su diseño y mecanismos de protección implementados.
\end{itemize}


