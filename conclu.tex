\begin{conclusion}

Como se expuso en el presente trabajo, el inminente crecimiento de las redes de computadoras y el explosivo aumento en el uso de distintos dispositivos que demandan conectividad hacen que volver la Internet más robusta, disponible y eficiente sea una prioridad. Entendiendo como parte crucial de dicha labor el trabajo del servicio DNS, postular mejoras que optimicen su operación es un ejercicio plenamente justificado en pos de brindar una mejor performance sobre la red. Es tras ese afán --y apoyado en un fundamento teórico probado-- que se han realizado distintos esfuerzos por mejorar el rendimiento en el consumo de datos desde una interfaz lógica de red incorporando paralelismo, pero sin los resultados esperados. 
 
 
A lo largo de esta investigación se repasaron las principales sospechas vigentes que tratan de dar explicación al mal rendimiento presentado en el consumo concurrente de datos desde una interfaz de red, dividiendo el problema en 3 estudios: 
 
 
A través del \textbf{estudio de operación de las primitivas de sincronización del sistema} se corroboró que frente a condiciones de concurrencia, la actividad de sincronización dada por las llamadas a funciones de dicho tipo se incrementa a medida que se usan más hilos en el consumo de datos, volviéndose cada vez más significativa éste tipo de funciones tanto en términos porcentuales como en términos del tiempo de ejecución total. Se determinó además que el protagonismo en dichas llamadas está asociado al control de bloqueo de spinlocks que protegen los sockets y que la tendencia en la duración de estas llamadas se ajusta de manera muy exacta a una curva de tipo logarítmico, algo interesante pues se rige por la misma tendencia que se determinó dominaba en el registro de tiempos netos de consumo de datos del caso de estudio, marcando una correlación directa entre ambos fenómenos y dando a entender que el control del spinlock termina impactando directamente en los tiempos totales de operación del socket. 
 
 
Con respecto al \textbf{estudio de canales de comunicación de hardware}, centrado en la dinámica de los \emph{performance counters} disponibles en el sistema, se logró corroborar el comportamiento entre componentes de hardware y cómo dicha dinámica se vuelve caótica a medida que se emplea una solución basada en concurrencia sobre un mismo socket, ello apoyado en el explosivo incremento de eventos como correcciones de caché, predicciones de procesamiento erróneas y rescate de datos de distintos niveles de memoria, entre otros. Más aún, este estudio demostró que el sistema --como un conjunto-- presenta un comportamiento explosivo en todas las aristas estudiadas, evidenciado en una alta correlación entre los eventos registrados al evaluarlos en un régimen concurrente. Nuevamente, se obtuvieron resultados que avalaban la sospecha de que la estructura socket no presenta un rendimiento escalable a medida que se incorporan operaciones concurrentes, reafirmando la hipótesis de que dicha estructura no tendría un diseño compatible con estrategias de consumo paralelo como las evaluadas. 
 
 
Por otro lado, nuestro \textbf{estudio de distribución de carga} usando \emph{processor affinity} demostró que aún cuando la arquitectura NUMA evaluada está optimizada para un mejor rendimiento basada en un procesamiento con datos distribuidos, las estrategias usadas para la asociación de hilos de ejecución a distintos cores no mostró ningún beneficio práctico. Más aún, se concluyó por una parte que al intentar aprovechar los distintos núcleos de procesamiento se cae en la misma situación detectada al usar concurrencia, ello pues los recursos terminan dispersándose entre los nodos NUMA y sus subestructuras de almacenamiento de datos, perdiendo el beneficio dado por el principio de localidad de memoria, y haciendo más dificil la coordinación en el acceso al socket mismo. Y por otro lado, que la aplicación de esquemas que reúnen los hilos en una misma componente de procesamiento termina por serialziar los accesos concurrentes, brindando un rendimiento equivalente a usar un sólo hilo. El comportamiento anterior concluye que las estratégias de procesamiento distribuido entre cores no brindan beneficio alguno pues a pesar de estar distribuyendo la carga de procesamiento se mantiene un mismo cuello de botella en el acceso por concepto del mecanismo de protección del socket compartido (nuevamente, el spinlock del socket). 
 
 
De esta forma, se pudo corroborar responsabilidades transversales y cruzadas entre las sospechas vigentes del problema estudiado. Transversales pues todas las sospechas resultaron ser corroboradas experimentalmente, dando a entender que --En mayor o menor grado-- el diseño de operación de las interfaces de red de Linux no incorpora en su diseño una aplicación que admita concurrencia en el consumo de información, limitando así la capacidad de optimizaciones usando la estrategia de paralelismo a secas. Y Cruzadas, en el sentido de que los factores responsables de cada sospecha resultan repetirse entre cada caso --siendo principal actor en este sentido el spinlock de protección de la estructura socket--. 
 
 
Como diagnostico final reuniendo las principales conclusiones de los tres estudios contemplados en la presente investigación se concluye que, tal y como se postuló como hipótesis inicial, la estructura socket implementada a nivel del kernel de Linux no es apta para operar correctamente en condiciones de concurrencia, ello debido a que la misma no estaría diseñada para soportar dinámicas de acceso paralelo. Por otro lado, se concluye también que la arquitectura NUMA evaluada no puede sacar verdadero provecho del paralelismo sobre una estructura socket pues, por su diseño, los mecanismos de protección de spinlocks asociados a los sockets producen efectos de cuello de botella que terminan impactando negativamente al sistema al sobrecargar los mecanismos de coherencia y corrección de caché. En este escenario, resulta incompatible la aplicación de verdadera distribución de trabajo entre distintas componentes de procesamiento cuando se tiene un punto de contención detectado que fuerza una dinámica de serialziación en el acceso al socket, entorpeciendo la coordinación de los distintos hilos que acceden al socket y terminando por degradar los tiempos netos de operación. 
 
 
Resulta interesante el que, al día de hoy, el problema estudiado sigue vigente y abierto a nuevas propuestas de soluciones. En esta misma línea, recientemente Facebook, a través de su equipo de desarrollo de kernel ha postulado modificaciones al núcleo de Linux que permitan hacer un uso más flexible en el consumo concurrente de datos desde estructuras protegidas por medio de estructuras denominadas \emph{Blk-mq} \cite{post:facebookFin}, que van en busca de aprovechar consumo distribuidos de colas usando lecturas exclusivas por cada CPU. Un enfoque que aprovecharía de mejor manera las interacciones de hardware del sistema al tener accesos más localizados que lo detectado en nuestro estudio de \emph{performance counters} e inspirado sobre la misma idea que nuestro estudio de \emph{processor affinity} pero implementado directamente a nivel del kernel. Por otro lado, una reciente publicacion de la revista \emph{;login;} de Usenix \cite{magazine:login} presentó un articulo sobre cómo aprovechar arquitecturas NUMA a modo de incrementar el rendimiento de operaciones sobre estructuras compartidas apoyándose en un estudio basado en performance counters, un enfoque muy similar al que se repasó en nuestra investigación combinando los enfoques de los estudios de \emph{performance counters} y \emph{processor affinity}, mostrando que las estratégias de análisis aplicadas en el presente trabajo están plenamente vigentes y siendo empleadas en investigaciones de alto nivel para sistemas y problemas actuales. 
 
 
Para cerrar, se postuló una solución basada en un módulo del kernel para Linux que, bajo un escenario de operación fiel al caso de estudio presentado, se presenta plenamente comparable con reuseport --La mejor opción disponible para palear el problema estudiado en cuestión-- siendo a la vez competitivo en rendimiento con este último, brindando en la práctica un desempeño que es muy similar. Por otro lado, la solución desarrollada cuenta con varios aciertos que la distinguen de reuseport: Una característica de balanceo de trabajo que ni el mismo reuseport incorpora, la que brinda una distribución de tiempos de trabajo más equitativa entre los sockets que trabajan conjuntamente, con respecto a reuseport. Por otro lado, Ser una solución extensible y modificable, lo que garantiza su fácil adaptación para escenarios de operación específicos e incluso la capacidad de portar la misma a otras plataformas. Finalmente, ser un desarrollo modular (Al ser un módulo del kernel), característica que permite postular la solución como una alternativa válida sobre cualquier entorno sobre Linux y poco invasivo con respecto al resto del sistema.

\end{conclusion}